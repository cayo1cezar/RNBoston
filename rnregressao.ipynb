{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUH+26XmDOYOZzgTxdlu8X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cayo1cezar/RNBoston/blob/main/rnregressao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VBHg60E-dbm",
        "outputId": "ab549216-4103-499a-9f4a-95a8f0d8b403"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_boston \n",
        "import pandas as pd\n",
        "boston = load_boston()\n",
        "x = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
        "y = boston.target"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UH9LdNtSAIqT",
        "outputId": "06cb42f7-9d94-472b-aa23-f5f9225f1ec4"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
              "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
              "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
              "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
              "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
              "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
              "\n",
              "   PTRATIO       B  LSTAT  \n",
              "0     15.3  396.90   4.98  \n",
              "1     17.8  396.90   9.14  \n",
              "2     17.8  392.83   4.03  \n",
              "3     18.7  394.63   2.94  \n",
              "4     18.7  396.90   5.33  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-508bc950-cc22-4607-bd37-2244e58a80d5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-508bc950-cc22-4607-bd37-2244e58a80d5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-508bc950-cc22-4607-bd37-2244e58a80d5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-508bc950-cc22-4607-bd37-2244e58a80d5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split  \n",
        "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size= 0.3) "
      ],
      "metadata": {
        "id": "iWwsz-FMAKcf"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Activation, Dropout \n",
        "\n",
        "modelo = Sequential()\n",
        "modelo.add(Dense(20, input_dim=13, kernel_initializer='normal', activation= 'relu'))\n",
        "modelo.add(Dense(20, kernel_initializer='normal', activation='relu'))\n",
        "modelo.add(Dense(1, kernel_initializer='normal', activation='linear'))\n",
        "\n",
        "from keras.optimizers import Adam \n",
        "otimizador = Adam()\n",
        "\n",
        "modelo.compile(loss=\"mean_squared_error\", optimizer=otimizador, metrics=['mae'])\n"
      ],
      "metadata": {
        "id": "0WwA_jyHAnls"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_treino.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0ERih1aBx79",
        "outputId": "10275bcb-7a02-4948-d44f-351d59f4291b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(354, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "historico = modelo.fit(x_treino, y_treino, epochs=1000, batch_size=354, validation_data=(x_teste, y_teste), verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2Am-VkYB0PF",
        "outputId": "18e00d3f-423a-45ae-d674-c52610a684ee"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1/1 [==============================] - 1s 547ms/step - loss: 617.3019 - mae: 23.1206 - val_loss: 609.8708 - val_mae: 22.9411\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 603.3844 - mae: 22.8075 - val_loss: 596.2459 - val_mae: 22.6282\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 589.3990 - mae: 22.4889 - val_loss: 582.4565 - val_mae: 22.3076\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 575.3021 - mae: 22.1634 - val_loss: 568.4918 - val_mae: 21.9782\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 561.0340 - mae: 21.8288 - val_loss: 554.6293 - val_mae: 21.6449\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 546.8181 - mae: 21.4897 - val_loss: 541.1743 - val_mae: 21.3180\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 533.1628 - mae: 21.1596 - val_loss: 527.4506 - val_mae: 20.9829\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 519.0698 - mae: 20.8161 - val_loss: 513.2654 - val_mae: 20.6301\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 504.4943 - mae: 20.4550 - val_loss: 498.9278 - val_mae: 20.2702\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 489.9499 - mae: 20.0894 - val_loss: 485.0113 - val_mae: 19.9189\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 476.0596 - mae: 19.7376 - val_loss: 472.2339 - val_mae: 19.5849\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 463.2769 - mae: 19.4008 - val_loss: 459.4088 - val_mae: 19.2369\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 450.2575 - mae: 19.0476 - val_loss: 445.9718 - val_mae: 18.8665\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 436.5692 - mae: 18.6689 - val_loss: 431.8881 - val_mae: 18.4768\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 422.2277 - mae: 18.2656 - val_loss: 417.1732 - val_mae: 18.0655\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 407.2598 - mae: 17.8340 - val_loss: 401.8785 - val_mae: 17.6260\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 391.7107 - mae: 17.3751 - val_loss: 386.0515 - val_mae: 17.1707\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 375.6302 - mae: 16.8932 - val_loss: 369.7352 - val_mae: 16.6910\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 359.0705 - mae: 16.3836 - val_loss: 353.0049 - val_mae: 16.1812\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 342.1170 - mae: 15.8546 - val_loss: 335.9318 - val_mae: 15.6442\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 324.8436 - mae: 15.3012 - val_loss: 318.6035 - val_mae: 15.1008\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 307.3419 - mae: 14.7287 - val_loss: 301.1202 - val_mae: 14.5383\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 289.7090 - mae: 14.1424 - val_loss: 283.6049 - val_mae: 13.9560\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 272.0757 - mae: 13.5508 - val_loss: 266.1978 - val_mae: 13.3658\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 254.5975 - mae: 12.9828 - val_loss: 249.0654 - val_mae: 12.7722\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 237.4440 - mae: 12.4288 - val_loss: 232.3959 - val_mae: 12.1804\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 220.8088 - mae: 11.8906 - val_loss: 216.3976 - val_mae: 11.5866\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 204.9089 - mae: 11.3581 - val_loss: 201.2938 - val_mae: 11.0019\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 189.9753 - mae: 10.8463 - val_loss: 187.3170 - val_mae: 10.4542\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 176.2480 - mae: 10.3685 - val_loss: 174.6998 - val_mae: 9.9374\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 163.9661 - mae: 9.9612 - val_loss: 163.6627 - val_mae: 9.4853\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 153.3553 - mae: 9.6132 - val_loss: 154.3983 - val_mae: 9.1089\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 144.6095 - mae: 9.3428 - val_loss: 147.0398 - val_mae: 8.8502\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 137.8625 - mae: 9.1284 - val_loss: 141.6500 - val_mae: 8.6994\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 133.1659 - mae: 8.9748 - val_loss: 138.0918 - val_mae: 8.6351\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 130.3713 - mae: 8.8663 - val_loss: 136.2630 - val_mae: 8.6325\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 129.3634 - mae: 8.8108 - val_loss: 135.9296 - val_mae: 8.6817\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 129.8849 - mae: 8.7985 - val_loss: 136.6398 - val_mae: 8.7522\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 131.4276 - mae: 8.8354 - val_loss: 137.9515 - val_mae: 8.8186\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 133.4553 - mae: 8.8825 - val_loss: 139.3396 - val_mae: 8.8887\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 135.4563 - mae: 8.9358 - val_loss: 140.3919 - val_mae: 8.9503\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 137.0044 - mae: 8.9781 - val_loss: 140.8261 - val_mae: 8.9817\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 137.8026 - mae: 8.9965 - val_loss: 140.5042 - val_mae: 8.9772\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 137.7090 - mae: 8.9899 - val_loss: 139.4283 - val_mae: 8.9359\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 136.7322 - mae: 8.9551 - val_loss: 137.7145 - val_mae: 8.8627\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 135.0032 - mae: 8.8954 - val_loss: 135.5535 - val_mae: 8.7650\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 132.7329 - mae: 8.8174 - val_loss: 133.1680 - val_mae: 8.6505\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 130.1673 - mae: 8.7277 - val_loss: 130.7756 - val_mae: 8.5293\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 127.5474 - mae: 8.6335 - val_loss: 128.5606 - val_mae: 8.4151\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 125.0796 - mae: 8.5474 - val_loss: 126.6561 - val_mae: 8.3151\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 122.9167 - mae: 8.4698 - val_loss: 125.1368 - val_mae: 8.2168\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 121.1496 - mae: 8.4059 - val_loss: 124.0204 - val_mae: 8.1273\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 119.8081 - mae: 8.3559 - val_loss: 123.2736 - val_mae: 8.0558\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 118.8684 - mae: 8.3211 - val_loss: 122.8246 - val_mae: 8.0090\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 118.2651 - mae: 8.2954 - val_loss: 122.5770 - val_mae: 7.9655\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 117.9057 - mae: 8.2781 - val_loss: 122.4249 - val_mae: 7.9268\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 117.6863 - mae: 8.2652 - val_loss: 122.2679 - val_mae: 7.8928\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 117.5069 - mae: 8.2506 - val_loss: 122.0228 - val_mae: 7.8627\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 117.2830 - mae: 8.2328 - val_loss: 121.6316 - val_mae: 7.8319\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 116.9540 - mae: 8.2113 - val_loss: 121.0636 - val_mae: 7.7990\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 116.4867 - mae: 8.1850 - val_loss: 120.3147 - val_mae: 7.7634\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 115.8736 - mae: 8.1539 - val_loss: 119.4023 - val_mae: 7.7254\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 115.1287 - mae: 8.1188 - val_loss: 118.3595 - val_mae: 7.6869\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 114.2815 - mae: 8.0801 - val_loss: 117.2285 - val_mae: 7.6486\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 113.3702 - mae: 8.0394 - val_loss: 116.0542 - val_mae: 7.6110\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 112.4357 - mae: 7.9973 - val_loss: 114.8792 - val_mae: 7.5734\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 111.5159 - mae: 7.9559 - val_loss: 113.7393 - val_mae: 7.5392\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 110.6419 - mae: 7.9145 - val_loss: 112.6608 - val_mae: 7.5079\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 109.8351 - mae: 7.8770 - val_loss: 111.6591 - val_mae: 7.4773\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 109.1058 - mae: 7.8430 - val_loss: 110.7389 - val_mae: 7.4499\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 108.4535 - mae: 7.8121 - val_loss: 109.8954 - val_mae: 7.4293\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 107.8686 - mae: 7.7834 - val_loss: 109.1168 - val_mae: 7.4100\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 107.3349 - mae: 7.7585 - val_loss: 108.3870 - val_mae: 7.3901\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 106.8327 - mae: 7.7353 - val_loss: 107.6890 - val_mae: 7.3696\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 106.3421 - mae: 7.7119 - val_loss: 107.0070 - val_mae: 7.3469\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 105.8456 - mae: 7.6877 - val_loss: 106.3291 - val_mae: 7.3223\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 105.3304 - mae: 7.6625 - val_loss: 105.6478 - val_mae: 7.2956\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 104.7895 - mae: 7.6363 - val_loss: 104.9605 - val_mae: 7.2655\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 104.2215 - mae: 7.6086 - val_loss: 104.2687 - val_mae: 7.2322\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 103.6300 - mae: 7.5797 - val_loss: 103.5768 - val_mae: 7.1961\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 103.0222 - mae: 7.5493 - val_loss: 102.8907 - val_mae: 7.1596\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 102.4071 - mae: 7.5177 - val_loss: 102.2161 - val_mae: 7.1222\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 101.7940 - mae: 7.4853 - val_loss: 101.5575 - val_mae: 7.0838\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 101.1907 - mae: 7.4524 - val_loss: 100.9175 - val_mae: 7.0449\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 100.6031 - mae: 7.4192 - val_loss: 100.2960 - val_mae: 7.0060\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 100.0340 - mae: 7.3864 - val_loss: 99.6907 - val_mae: 6.9675\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 99.4838 - mae: 7.3539 - val_loss: 99.0975 - val_mae: 6.9311\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 98.9506 - mae: 7.3220 - val_loss: 98.5111 - val_mae: 6.8976\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 98.4309 - mae: 7.2924 - val_loss: 97.9260 - val_mae: 6.8651\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 97.9202 - mae: 7.2633 - val_loss: 97.3370 - val_mae: 6.8334\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 97.4144 - mae: 7.2346 - val_loss: 96.7396 - val_mae: 6.8024\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 96.9097 - mae: 7.2064 - val_loss: 96.1318 - val_mae: 6.7744\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 96.4038 - mae: 7.1786 - val_loss: 95.5130 - val_mae: 6.7475\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 95.8953 - mae: 7.1517 - val_loss: 94.8835 - val_mae: 6.7213\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 95.3848 - mae: 7.1262 - val_loss: 94.2452 - val_mae: 6.6959\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 94.8728 - mae: 7.1020 - val_loss: 93.6016 - val_mae: 6.6718\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 94.3611 - mae: 7.0784 - val_loss: 92.9561 - val_mae: 6.6494\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 93.8515 - mae: 7.0552 - val_loss: 92.3122 - val_mae: 6.6294\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 93.3465 - mae: 7.0332 - val_loss: 91.6739 - val_mae: 6.6102\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 92.8470 - mae: 7.0120 - val_loss: 91.0428 - val_mae: 6.5923\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 92.3544 - mae: 6.9908 - val_loss: 90.4205 - val_mae: 6.5758\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 91.8691 - mae: 6.9698 - val_loss: 89.8071 - val_mae: 6.5595\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 91.3910 - mae: 6.9496 - val_loss: 89.2034 - val_mae: 6.5434\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 90.9194 - mae: 6.9289 - val_loss: 88.6095 - val_mae: 6.5263\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 90.4533 - mae: 6.9084 - val_loss: 88.0251 - val_mae: 6.5083\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 89.9917 - mae: 6.8886 - val_loss: 87.4494 - val_mae: 6.4893\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 89.5340 - mae: 6.8692 - val_loss: 86.8817 - val_mae: 6.4692\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 89.0798 - mae: 6.8490 - val_loss: 86.3217 - val_mae: 6.4485\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 88.6283 - mae: 6.8288 - val_loss: 85.7689 - val_mae: 6.4275\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 88.1796 - mae: 6.8080 - val_loss: 85.2231 - val_mae: 6.4055\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 87.7344 - mae: 6.7865 - val_loss: 84.6843 - val_mae: 6.3829\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 87.2934 - mae: 6.7652 - val_loss: 84.1525 - val_mae: 6.3612\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 86.8575 - mae: 6.7437 - val_loss: 83.6274 - val_mae: 6.3389\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 86.4270 - mae: 6.7218 - val_loss: 83.1090 - val_mae: 6.3164\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 86.0021 - mae: 6.6999 - val_loss: 82.5968 - val_mae: 6.2941\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 85.5829 - mae: 6.6780 - val_loss: 82.0903 - val_mae: 6.2723\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 85.1695 - mae: 6.6564 - val_loss: 81.5886 - val_mae: 6.2504\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 84.7618 - mae: 6.6355 - val_loss: 81.0914 - val_mae: 6.2303\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 84.3599 - mae: 6.6151 - val_loss: 80.5984 - val_mae: 6.2112\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 83.9635 - mae: 6.5957 - val_loss: 80.1095 - val_mae: 6.1926\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 83.5725 - mae: 6.5771 - val_loss: 79.6244 - val_mae: 6.1747\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 83.1871 - mae: 6.5590 - val_loss: 79.1428 - val_mae: 6.1577\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 82.8069 - mae: 6.5414 - val_loss: 78.6647 - val_mae: 6.1415\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 82.4319 - mae: 6.5243 - val_loss: 78.1911 - val_mae: 6.1278\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 82.0622 - mae: 6.5079 - val_loss: 77.7226 - val_mae: 6.1145\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 81.6979 - mae: 6.4924 - val_loss: 77.2596 - val_mae: 6.1026\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 81.3396 - mae: 6.4773 - val_loss: 76.8028 - val_mae: 6.0936\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 80.9874 - mae: 6.4634 - val_loss: 76.3529 - val_mae: 6.0853\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 80.6413 - mae: 6.4495 - val_loss: 75.9101 - val_mae: 6.0773\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 80.3017 - mae: 6.4358 - val_loss: 75.4744 - val_mae: 6.0692\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 79.9676 - mae: 6.4226 - val_loss: 75.0452 - val_mae: 6.0613\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 79.6384 - mae: 6.4094 - val_loss: 74.6230 - val_mae: 6.0536\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 79.3152 - mae: 6.3958 - val_loss: 74.2081 - val_mae: 6.0461\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 78.9974 - mae: 6.3821 - val_loss: 73.8007 - val_mae: 6.0385\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 78.6845 - mae: 6.3680 - val_loss: 73.3999 - val_mae: 6.0303\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 78.3775 - mae: 6.3542 - val_loss: 73.0061 - val_mae: 6.0217\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 78.0763 - mae: 6.3409 - val_loss: 72.6185 - val_mae: 6.0125\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 77.7801 - mae: 6.3272 - val_loss: 72.2357 - val_mae: 6.0027\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 77.4889 - mae: 6.3138 - val_loss: 71.8541 - val_mae: 5.9922\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 77.2025 - mae: 6.3010 - val_loss: 71.4786 - val_mae: 5.9814\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 76.9220 - mae: 6.2887 - val_loss: 71.1085 - val_mae: 5.9725\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 76.6474 - mae: 6.2767 - val_loss: 70.7436 - val_mae: 5.9636\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 76.3783 - mae: 6.2644 - val_loss: 70.3841 - val_mae: 5.9547\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 76.1152 - mae: 6.2523 - val_loss: 70.0307 - val_mae: 5.9463\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 75.8557 - mae: 6.2404 - val_loss: 69.6818 - val_mae: 5.9380\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 75.6005 - mae: 6.2290 - val_loss: 69.3381 - val_mae: 5.9298\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 75.3508 - mae: 6.2193 - val_loss: 68.9985 - val_mae: 5.9216\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 75.1062 - mae: 6.2099 - val_loss: 68.6623 - val_mae: 5.9133\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 74.8658 - mae: 6.2004 - val_loss: 68.3306 - val_mae: 5.9051\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 74.6283 - mae: 6.1912 - val_loss: 68.0022 - val_mae: 5.8975\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 74.3951 - mae: 6.1823 - val_loss: 67.6764 - val_mae: 5.8896\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 74.1666 - mae: 6.1737 - val_loss: 67.3533 - val_mae: 5.8815\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 73.9412 - mae: 6.1652 - val_loss: 67.0345 - val_mae: 5.8733\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 73.7196 - mae: 6.1569 - val_loss: 66.7204 - val_mae: 5.8649\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 73.5017 - mae: 6.1485 - val_loss: 66.4105 - val_mae: 5.8562\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 73.2873 - mae: 6.1399 - val_loss: 66.1043 - val_mae: 5.8471\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 73.0757 - mae: 6.1320 - val_loss: 65.8004 - val_mae: 5.8381\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 72.8680 - mae: 6.1243 - val_loss: 65.4998 - val_mae: 5.8298\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 72.6646 - mae: 6.1164 - val_loss: 65.2037 - val_mae: 5.8213\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 72.4655 - mae: 6.1085 - val_loss: 64.9117 - val_mae: 5.8127\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 72.2701 - mae: 6.1003 - val_loss: 64.6241 - val_mae: 5.8047\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 72.0789 - mae: 6.0922 - val_loss: 64.3389 - val_mae: 5.7968\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 71.8926 - mae: 6.0844 - val_loss: 64.0579 - val_mae: 5.7889\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 71.7108 - mae: 6.0775 - val_loss: 63.7828 - val_mae: 5.7810\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 71.5349 - mae: 6.0709 - val_loss: 63.5160 - val_mae: 5.7734\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 71.3630 - mae: 6.0644 - val_loss: 63.2532 - val_mae: 5.7663\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 71.1949 - mae: 6.0579 - val_loss: 62.9947 - val_mae: 5.7592\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 71.0313 - mae: 6.0515 - val_loss: 62.7431 - val_mae: 5.7532\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 70.8733 - mae: 6.0452 - val_loss: 62.5080 - val_mae: 5.7477\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 70.7197 - mae: 6.0390 - val_loss: 62.2817 - val_mae: 5.7422\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 70.5702 - mae: 6.0332 - val_loss: 62.0622 - val_mae: 5.7367\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 70.4245 - mae: 6.0278 - val_loss: 61.8475 - val_mae: 5.7311\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 70.2832 - mae: 6.0225 - val_loss: 61.6376 - val_mae: 5.7255\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 70.1469 - mae: 6.0173 - val_loss: 61.4415 - val_mae: 5.7206\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 70.0152 - mae: 6.0122 - val_loss: 61.2520 - val_mae: 5.7165\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 69.8888 - mae: 6.0078 - val_loss: 61.0671 - val_mae: 5.7128\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 69.7679 - mae: 6.0037 - val_loss: 60.8882 - val_mae: 5.7093\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 69.6508 - mae: 5.9998 - val_loss: 60.7122 - val_mae: 5.7057\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 69.5383 - mae: 5.9961 - val_loss: 60.5364 - val_mae: 5.7018\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 69.4330 - mae: 5.9921 - val_loss: 60.3616 - val_mae: 5.6976\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 69.3309 - mae: 5.9874 - val_loss: 60.1883 - val_mae: 5.6937\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 69.2306 - mae: 5.9826 - val_loss: 60.0157 - val_mae: 5.6894\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 69.1317 - mae: 5.9776 - val_loss: 59.8401 - val_mae: 5.6847\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 69.0362 - mae: 5.9724 - val_loss: 59.6652 - val_mae: 5.6798\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 68.9463 - mae: 5.9673 - val_loss: 59.4926 - val_mae: 5.6750\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 68.8593 - mae: 5.9624 - val_loss: 59.3218 - val_mae: 5.6703\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 68.7727 - mae: 5.9578 - val_loss: 59.1589 - val_mae: 5.6661\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 68.6884 - mae: 5.9536 - val_loss: 58.9998 - val_mae: 5.6621\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 68.6051 - mae: 5.9497 - val_loss: 58.8430 - val_mae: 5.6583\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 68.5226 - mae: 5.9463 - val_loss: 58.6886 - val_mae: 5.6547\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 68.4421 - mae: 5.9433 - val_loss: 58.5379 - val_mae: 5.6518\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 68.3639 - mae: 5.9412 - val_loss: 58.3919 - val_mae: 5.6499\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 68.2895 - mae: 5.9399 - val_loss: 58.2554 - val_mae: 5.6484\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 68.2169 - mae: 5.9392 - val_loss: 58.1230 - val_mae: 5.6470\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 68.1415 - mae: 5.9387 - val_loss: 57.9935 - val_mae: 5.6455\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 68.0661 - mae: 5.9380 - val_loss: 57.8659 - val_mae: 5.6437\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 67.9918 - mae: 5.9368 - val_loss: 57.7392 - val_mae: 5.6413\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 67.9196 - mae: 5.9351 - val_loss: 57.6149 - val_mae: 5.6386\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 67.8470 - mae: 5.9325 - val_loss: 57.5007 - val_mae: 5.6356\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 67.7740 - mae: 5.9291 - val_loss: 57.3888 - val_mae: 5.6320\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 67.6980 - mae: 5.9246 - val_loss: 57.2785 - val_mae: 5.6283\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 67.6264 - mae: 5.9197 - val_loss: 57.1712 - val_mae: 5.6245\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 67.5570 - mae: 5.9143 - val_loss: 57.0680 - val_mae: 5.6206\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 67.4892 - mae: 5.9087 - val_loss: 56.9655 - val_mae: 5.6166\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 67.4217 - mae: 5.9030 - val_loss: 56.8629 - val_mae: 5.6123\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 67.3556 - mae: 5.8973 - val_loss: 56.7612 - val_mae: 5.6081\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 67.2913 - mae: 5.8920 - val_loss: 56.6632 - val_mae: 5.6044\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 67.2298 - mae: 5.8874 - val_loss: 56.5658 - val_mae: 5.6011\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 67.1701 - mae: 5.8835 - val_loss: 56.4683 - val_mae: 5.5980\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 67.1092 - mae: 5.8803 - val_loss: 56.3729 - val_mae: 5.5955\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 67.0476 - mae: 5.8777 - val_loss: 56.2784 - val_mae: 5.5933\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 66.9848 - mae: 5.8755 - val_loss: 56.1843 - val_mae: 5.5912\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 66.9211 - mae: 5.8735 - val_loss: 56.0899 - val_mae: 5.5889\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 66.8575 - mae: 5.8714 - val_loss: 55.9957 - val_mae: 5.5866\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 66.7937 - mae: 5.8692 - val_loss: 55.9011 - val_mae: 5.5840\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 66.7294 - mae: 5.8666 - val_loss: 55.8061 - val_mae: 5.5813\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 66.6650 - mae: 5.8637 - val_loss: 55.7106 - val_mae: 5.5783\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 66.6005 - mae: 5.8603 - val_loss: 55.6148 - val_mae: 5.5750\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 66.5361 - mae: 5.8567 - val_loss: 55.5189 - val_mae: 5.5714\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 66.4720 - mae: 5.8528 - val_loss: 55.4231 - val_mae: 5.5678\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 66.4072 - mae: 5.8486 - val_loss: 55.3273 - val_mae: 5.5640\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 66.3416 - mae: 5.8444 - val_loss: 55.2317 - val_mae: 5.5601\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 66.2752 - mae: 5.8401 - val_loss: 55.1360 - val_mae: 5.5562\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 66.2062 - mae: 5.8359 - val_loss: 55.0401 - val_mae: 5.5523\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 66.1353 - mae: 5.8316 - val_loss: 54.9421 - val_mae: 5.5482\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 66.0626 - mae: 5.8271 - val_loss: 54.8420 - val_mae: 5.5439\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 65.9889 - mae: 5.8224 - val_loss: 54.7394 - val_mae: 5.5394\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 65.9143 - mae: 5.8176 - val_loss: 54.6367 - val_mae: 5.5351\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 65.8373 - mae: 5.8130 - val_loss: 54.5350 - val_mae: 5.5312\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 65.7600 - mae: 5.8089 - val_loss: 54.4342 - val_mae: 5.5277\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 65.6830 - mae: 5.8053 - val_loss: 54.3341 - val_mae: 5.5243\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 65.6074 - mae: 5.8020 - val_loss: 54.2339 - val_mae: 5.5208\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 65.5325 - mae: 5.7987 - val_loss: 54.1325 - val_mae: 5.5168\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 65.4582 - mae: 5.7948 - val_loss: 54.0295 - val_mae: 5.5122\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 65.3848 - mae: 5.7903 - val_loss: 53.9264 - val_mae: 5.5074\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 65.3110 - mae: 5.7856 - val_loss: 53.8234 - val_mae: 5.5023\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 65.2364 - mae: 5.7805 - val_loss: 53.7214 - val_mae: 5.4971\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 65.1606 - mae: 5.7752 - val_loss: 53.6196 - val_mae: 5.4917\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 65.0845 - mae: 5.7697 - val_loss: 53.5181 - val_mae: 5.4863\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 65.0080 - mae: 5.7643 - val_loss: 53.4158 - val_mae: 5.4807\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 64.9308 - mae: 5.7587 - val_loss: 53.3129 - val_mae: 5.4751\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 64.8531 - mae: 5.7529 - val_loss: 53.2112 - val_mae: 5.4697\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 64.7753 - mae: 5.7475 - val_loss: 53.1108 - val_mae: 5.4647\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 64.6974 - mae: 5.7425 - val_loss: 53.0099 - val_mae: 5.4596\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 64.6194 - mae: 5.7375 - val_loss: 52.9087 - val_mae: 5.4545\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 64.5414 - mae: 5.7326 - val_loss: 52.8068 - val_mae: 5.4495\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 64.4636 - mae: 5.7279 - val_loss: 52.7062 - val_mae: 5.4447\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 64.3862 - mae: 5.7234 - val_loss: 52.6070 - val_mae: 5.4401\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 64.3085 - mae: 5.7190 - val_loss: 52.5089 - val_mae: 5.4357\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 64.2313 - mae: 5.7149 - val_loss: 52.4142 - val_mae: 5.4319\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 64.1543 - mae: 5.7114 - val_loss: 52.3207 - val_mae: 5.4282\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 64.0778 - mae: 5.7080 - val_loss: 52.2280 - val_mae: 5.4245\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 64.0022 - mae: 5.7046 - val_loss: 52.1369 - val_mae: 5.4209\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 63.9270 - mae: 5.7016 - val_loss: 52.0457 - val_mae: 5.4172\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 63.8529 - mae: 5.6983 - val_loss: 51.9543 - val_mae: 5.4133\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 63.7793 - mae: 5.6948 - val_loss: 51.8639 - val_mae: 5.4094\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 63.7058 - mae: 5.6913 - val_loss: 51.7746 - val_mae: 5.4056\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 63.6331 - mae: 5.6877 - val_loss: 51.6851 - val_mae: 5.4014\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 63.5616 - mae: 5.6837 - val_loss: 51.5935 - val_mae: 5.3966\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 63.4900 - mae: 5.6792 - val_loss: 51.5024 - val_mae: 5.3916\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 63.4189 - mae: 5.6744 - val_loss: 51.4135 - val_mae: 5.3866\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 63.3484 - mae: 5.6696 - val_loss: 51.3258 - val_mae: 5.3818\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 63.2785 - mae: 5.6651 - val_loss: 51.2402 - val_mae: 5.3774\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 63.2088 - mae: 5.6608 - val_loss: 51.1559 - val_mae: 5.3730\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 63.1393 - mae: 5.6567 - val_loss: 51.0716 - val_mae: 5.3685\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 63.0709 - mae: 5.6526 - val_loss: 50.9875 - val_mae: 5.3640\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 63.0026 - mae: 5.6485 - val_loss: 50.9036 - val_mae: 5.3595\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 62.9347 - mae: 5.6443 - val_loss: 50.8203 - val_mae: 5.3551\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 62.8680 - mae: 5.6402 - val_loss: 50.7377 - val_mae: 5.3507\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 62.8016 - mae: 5.6361 - val_loss: 50.6572 - val_mae: 5.3465\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 62.7358 - mae: 5.6321 - val_loss: 50.5789 - val_mae: 5.3428\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 62.6701 - mae: 5.6286 - val_loss: 50.5035 - val_mae: 5.3394\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 62.6049 - mae: 5.6256 - val_loss: 50.4331 - val_mae: 5.3365\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 62.5409 - mae: 5.6230 - val_loss: 50.3657 - val_mae: 5.3339\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 62.4774 - mae: 5.6206 - val_loss: 50.2980 - val_mae: 5.3311\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 62.4137 - mae: 5.6179 - val_loss: 50.2294 - val_mae: 5.3280\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 62.3499 - mae: 5.6149 - val_loss: 50.1625 - val_mae: 5.3248\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 62.2864 - mae: 5.6119 - val_loss: 50.0971 - val_mae: 5.3217\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 62.2234 - mae: 5.6088 - val_loss: 50.0323 - val_mae: 5.3184\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 62.1612 - mae: 5.6056 - val_loss: 49.9673 - val_mae: 5.3148\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 62.0997 - mae: 5.6022 - val_loss: 49.9039 - val_mae: 5.3112\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 62.0391 - mae: 5.5988 - val_loss: 49.8428 - val_mae: 5.3080\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 61.9791 - mae: 5.5955 - val_loss: 49.7832 - val_mae: 5.3051\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 61.9200 - mae: 5.5923 - val_loss: 49.7253 - val_mae: 5.3022\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 61.8610 - mae: 5.5892 - val_loss: 49.6684 - val_mae: 5.2992\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 61.8021 - mae: 5.5858 - val_loss: 49.6128 - val_mae: 5.2962\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 61.7433 - mae: 5.5825 - val_loss: 49.5572 - val_mae: 5.2932\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 61.6845 - mae: 5.5793 - val_loss: 49.5009 - val_mae: 5.2901\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 61.6259 - mae: 5.5761 - val_loss: 49.4452 - val_mae: 5.2870\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 61.5682 - mae: 5.5731 - val_loss: 49.3905 - val_mae: 5.2842\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 61.5105 - mae: 5.5704 - val_loss: 49.3350 - val_mae: 5.2812\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 61.4531 - mae: 5.5675 - val_loss: 49.2804 - val_mae: 5.2785\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 61.3964 - mae: 5.5651 - val_loss: 49.2266 - val_mae: 5.2760\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 61.3401 - mae: 5.5629 - val_loss: 49.1739 - val_mae: 5.2737\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 61.2842 - mae: 5.5609 - val_loss: 49.1200 - val_mae: 5.2711\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 61.2276 - mae: 5.5585 - val_loss: 49.0674 - val_mae: 5.2684\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 61.1709 - mae: 5.5561 - val_loss: 49.0164 - val_mae: 5.2658\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 61.1141 - mae: 5.5536 - val_loss: 48.9654 - val_mae: 5.2631\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 61.0573 - mae: 5.5510 - val_loss: 48.9145 - val_mae: 5.2604\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 61.0006 - mae: 5.5483 - val_loss: 48.8637 - val_mae: 5.2576\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 60.9438 - mae: 5.5455 - val_loss: 48.8132 - val_mae: 5.2548\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 60.8870 - mae: 5.5427 - val_loss: 48.7628 - val_mae: 5.2519\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 60.8303 - mae: 5.5399 - val_loss: 48.7126 - val_mae: 5.2491\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 60.7740 - mae: 5.5371 - val_loss: 48.6612 - val_mae: 5.2460\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 60.7179 - mae: 5.5341 - val_loss: 48.6093 - val_mae: 5.2428\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 60.6620 - mae: 5.5310 - val_loss: 48.5574 - val_mae: 5.2396\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 60.6060 - mae: 5.5279 - val_loss: 48.5069 - val_mae: 5.2368\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 60.5499 - mae: 5.5251 - val_loss: 48.4574 - val_mae: 5.2342\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 60.4934 - mae: 5.5225 - val_loss: 48.4081 - val_mae: 5.2317\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 60.4366 - mae: 5.5201 - val_loss: 48.3604 - val_mae: 5.2296\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 60.3797 - mae: 5.5179 - val_loss: 48.3134 - val_mae: 5.2275\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 60.3226 - mae: 5.5157 - val_loss: 48.2668 - val_mae: 5.2255\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 60.2653 - mae: 5.5136 - val_loss: 48.2201 - val_mae: 5.2233\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 60.2078 - mae: 5.5112 - val_loss: 48.1725 - val_mae: 5.2209\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 60.1502 - mae: 5.5087 - val_loss: 48.1242 - val_mae: 5.2183\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 60.0928 - mae: 5.5060 - val_loss: 48.0753 - val_mae: 5.2157\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 60.0354 - mae: 5.5032 - val_loss: 48.0260 - val_mae: 5.2131\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 59.9777 - mae: 5.5005 - val_loss: 47.9763 - val_mae: 5.2104\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 59.9198 - mae: 5.4977 - val_loss: 47.9264 - val_mae: 5.2079\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 59.8617 - mae: 5.4950 - val_loss: 47.8769 - val_mae: 5.2055\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 59.8034 - mae: 5.4926 - val_loss: 47.8279 - val_mae: 5.2034\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 59.7447 - mae: 5.4903 - val_loss: 47.7794 - val_mae: 5.2014\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 59.6858 - mae: 5.4882 - val_loss: 47.7299 - val_mae: 5.1991\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 59.6267 - mae: 5.4858 - val_loss: 47.6796 - val_mae: 5.1967\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 59.5673 - mae: 5.4831 - val_loss: 47.6286 - val_mae: 5.1940\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 59.5076 - mae: 5.4803 - val_loss: 47.5778 - val_mae: 5.1915\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 59.4476 - mae: 5.4776 - val_loss: 47.5271 - val_mae: 5.1890\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 59.3873 - mae: 5.4749 - val_loss: 47.4764 - val_mae: 5.1866\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 59.3266 - mae: 5.4723 - val_loss: 47.4255 - val_mae: 5.1841\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 59.2656 - mae: 5.4696 - val_loss: 47.3743 - val_mae: 5.1814\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 59.2042 - mae: 5.4667 - val_loss: 47.3225 - val_mae: 5.1786\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 59.1425 - mae: 5.4635 - val_loss: 47.2700 - val_mae: 5.1755\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 59.0805 - mae: 5.4602 - val_loss: 47.2177 - val_mae: 5.1726\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 59.0181 - mae: 5.4571 - val_loss: 47.1655 - val_mae: 5.1698\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 58.9553 - mae: 5.4540 - val_loss: 47.1137 - val_mae: 5.1670\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 58.8921 - mae: 5.4510 - val_loss: 47.0617 - val_mae: 5.1643\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 58.8286 - mae: 5.4480 - val_loss: 47.0092 - val_mae: 5.1615\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 58.7647 - mae: 5.4449 - val_loss: 46.9563 - val_mae: 5.1586\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 58.7005 - mae: 5.4417 - val_loss: 46.9030 - val_mae: 5.1555\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 58.6358 - mae: 5.4384 - val_loss: 46.8492 - val_mae: 5.1524\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 58.5707 - mae: 5.4351 - val_loss: 46.7960 - val_mae: 5.1497\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 58.5053 - mae: 5.4321 - val_loss: 46.7431 - val_mae: 5.1472\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 58.4394 - mae: 5.4295 - val_loss: 46.6901 - val_mae: 5.1448\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 58.3731 - mae: 5.4269 - val_loss: 46.6366 - val_mae: 5.1424\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 58.3064 - mae: 5.4244 - val_loss: 46.5823 - val_mae: 5.1397\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 58.2392 - mae: 5.4216 - val_loss: 46.5278 - val_mae: 5.1371\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 58.1715 - mae: 5.4190 - val_loss: 46.4730 - val_mae: 5.1345\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 58.1034 - mae: 5.4164 - val_loss: 46.4168 - val_mae: 5.1314\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 58.0349 - mae: 5.4132 - val_loss: 46.3593 - val_mae: 5.1278\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 57.9658 - mae: 5.4096 - val_loss: 46.3013 - val_mae: 5.1241\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 57.8963 - mae: 5.4058 - val_loss: 46.2430 - val_mae: 5.1204\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 57.8262 - mae: 5.4021 - val_loss: 46.1845 - val_mae: 5.1168\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 57.7557 - mae: 5.3984 - val_loss: 46.1261 - val_mae: 5.1134\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 57.6846 - mae: 5.3951 - val_loss: 46.0672 - val_mae: 5.1100\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 57.6131 - mae: 5.3916 - val_loss: 46.0076 - val_mae: 5.1065\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 57.5410 - mae: 5.3882 - val_loss: 45.9475 - val_mae: 5.1029\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 57.4685 - mae: 5.3846 - val_loss: 45.8867 - val_mae: 5.0992\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 57.3954 - mae: 5.3809 - val_loss: 45.8253 - val_mae: 5.0954\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 57.3218 - mae: 5.3771 - val_loss: 45.7633 - val_mae: 5.0915\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 57.2476 - mae: 5.3733 - val_loss: 45.7014 - val_mae: 5.0880\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 57.1730 - mae: 5.3699 - val_loss: 45.6391 - val_mae: 5.0845\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 57.0978 - mae: 5.3665 - val_loss: 45.5755 - val_mae: 5.0806\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 57.0220 - mae: 5.3627 - val_loss: 45.5106 - val_mae: 5.0764\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 56.9455 - mae: 5.3585 - val_loss: 45.4445 - val_mae: 5.0719\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 56.8684 - mae: 5.3541 - val_loss: 45.3784 - val_mae: 5.0678\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 56.7908 - mae: 5.3501 - val_loss: 45.3123 - val_mae: 5.0639\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 56.7125 - mae: 5.3463 - val_loss: 45.2455 - val_mae: 5.0601\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 56.6338 - mae: 5.3426 - val_loss: 45.1782 - val_mae: 5.0562\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 56.5543 - mae: 5.3388 - val_loss: 45.1104 - val_mae: 5.0522\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 56.4743 - mae: 5.3349 - val_loss: 45.0419 - val_mae: 5.0482\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 56.3936 - mae: 5.3310 - val_loss: 44.9723 - val_mae: 5.0438\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 56.3124 - mae: 5.3268 - val_loss: 44.9020 - val_mae: 5.0393\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 56.2305 - mae: 5.3224 - val_loss: 44.8317 - val_mae: 5.0350\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 56.1480 - mae: 5.3183 - val_loss: 44.7616 - val_mae: 5.0310\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 56.0647 - mae: 5.3144 - val_loss: 44.6914 - val_mae: 5.0272\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 55.9808 - mae: 5.3109 - val_loss: 44.6202 - val_mae: 5.0231\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 55.8962 - mae: 5.3071 - val_loss: 44.5480 - val_mae: 5.0187\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 55.8108 - mae: 5.3028 - val_loss: 44.4746 - val_mae: 5.0140\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 55.7247 - mae: 5.2982 - val_loss: 44.4004 - val_mae: 5.0091\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 55.6379 - mae: 5.2934 - val_loss: 44.3261 - val_mae: 5.0045\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 55.5505 - mae: 5.2889 - val_loss: 44.2517 - val_mae: 5.0001\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 55.4622 - mae: 5.2848 - val_loss: 44.1770 - val_mae: 4.9960\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 55.3732 - mae: 5.2810 - val_loss: 44.1016 - val_mae: 4.9919\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 55.2836 - mae: 5.2771 - val_loss: 44.0244 - val_mae: 4.9870\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 55.1932 - mae: 5.2726 - val_loss: 43.9455 - val_mae: 4.9816\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 55.1018 - mae: 5.2674 - val_loss: 43.8650 - val_mae: 4.9757\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 55.0098 - mae: 5.2616 - val_loss: 43.7840 - val_mae: 4.9697\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 54.9170 - mae: 5.2558 - val_loss: 43.7027 - val_mae: 4.9638\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 54.8234 - mae: 5.2500 - val_loss: 43.6218 - val_mae: 4.9583\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 54.7290 - mae: 5.2448 - val_loss: 43.5413 - val_mae: 4.9533\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 54.6337 - mae: 5.2401 - val_loss: 43.4608 - val_mae: 4.9487\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 54.5375 - mae: 5.2358 - val_loss: 43.3796 - val_mae: 4.9437\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 54.4405 - mae: 5.2313 - val_loss: 43.2977 - val_mae: 4.9386\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 54.3427 - mae: 5.2265 - val_loss: 43.2145 - val_mae: 4.9330\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 54.2439 - mae: 5.2213 - val_loss: 43.1298 - val_mae: 4.9270\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 54.1442 - mae: 5.2156 - val_loss: 43.0439 - val_mae: 4.9205\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 54.0435 - mae: 5.2096 - val_loss: 42.9573 - val_mae: 4.9141\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 53.9419 - mae: 5.2036 - val_loss: 42.8701 - val_mae: 4.9076\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 53.8394 - mae: 5.1977 - val_loss: 42.7824 - val_mae: 4.9013\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 53.7360 - mae: 5.1919 - val_loss: 42.6939 - val_mae: 4.8949\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 53.6316 - mae: 5.1860 - val_loss: 42.6047 - val_mae: 4.8886\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 53.5263 - mae: 5.1803 - val_loss: 42.5153 - val_mae: 4.8826\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 53.4201 - mae: 5.1750 - val_loss: 42.4248 - val_mae: 4.8764\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 53.3130 - mae: 5.1695 - val_loss: 42.3331 - val_mae: 4.8700\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 53.2049 - mae: 5.1638 - val_loss: 42.2399 - val_mae: 4.8633\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 53.0958 - mae: 5.1577 - val_loss: 42.1462 - val_mae: 4.8568\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 52.9859 - mae: 5.1518 - val_loss: 42.0519 - val_mae: 4.8504\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 52.8750 - mae: 5.1458 - val_loss: 41.9567 - val_mae: 4.8439\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 52.7631 - mae: 5.1398 - val_loss: 41.8615 - val_mae: 4.8381\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 52.6498 - mae: 5.1343 - val_loss: 41.7658 - val_mae: 4.8326\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 52.5353 - mae: 5.1291 - val_loss: 41.6680 - val_mae: 4.8262\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 52.4199 - mae: 5.1229 - val_loss: 41.5694 - val_mae: 4.8199\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 52.3034 - mae: 5.1168 - val_loss: 41.4699 - val_mae: 4.8135\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 52.1859 - mae: 5.1106 - val_loss: 41.3686 - val_mae: 4.8065\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 52.0673 - mae: 5.1038 - val_loss: 41.2659 - val_mae: 4.7993\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 51.9478 - mae: 5.0969 - val_loss: 41.1621 - val_mae: 4.7922\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 51.8271 - mae: 5.0900 - val_loss: 41.0580 - val_mae: 4.7853\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 51.7048 - mae: 5.0836 - val_loss: 40.9529 - val_mae: 4.7783\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 51.5814 - mae: 5.0769 - val_loss: 40.8463 - val_mae: 4.7709\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 51.4570 - mae: 5.0699 - val_loss: 40.7383 - val_mae: 4.7631\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 51.3315 - mae: 5.0625 - val_loss: 40.6291 - val_mae: 4.7550\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 51.2050 - mae: 5.0548 - val_loss: 40.5197 - val_mae: 4.7473\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 51.0774 - mae: 5.0476 - val_loss: 40.4094 - val_mae: 4.7394\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 50.9488 - mae: 5.0405 - val_loss: 40.2988 - val_mae: 4.7316\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 50.8194 - mae: 5.0334 - val_loss: 40.1872 - val_mae: 4.7236\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 50.6889 - mae: 5.0263 - val_loss: 40.0745 - val_mae: 4.7156\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 50.5573 - mae: 5.0192 - val_loss: 39.9611 - val_mae: 4.7076\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 50.4247 - mae: 5.0122 - val_loss: 39.8472 - val_mae: 4.7000\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 50.2910 - mae: 5.0059 - val_loss: 39.7317 - val_mae: 4.6919\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 50.1563 - mae: 4.9990 - val_loss: 39.6144 - val_mae: 4.6834\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 50.0206 - mae: 4.9916 - val_loss: 39.4953 - val_mae: 4.6743\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 49.8839 - mae: 4.9835 - val_loss: 39.3748 - val_mae: 4.6649\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 49.7462 - mae: 4.9751 - val_loss: 39.2532 - val_mae: 4.6555\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 49.6074 - mae: 4.9668 - val_loss: 39.1297 - val_mae: 4.6461\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 49.4675 - mae: 4.9585 - val_loss: 39.0060 - val_mae: 4.6374\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 49.3266 - mae: 4.9511 - val_loss: 38.8808 - val_mae: 4.6286\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 49.1847 - mae: 4.9435 - val_loss: 38.7539 - val_mae: 4.6193\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 49.0418 - mae: 4.9353 - val_loss: 38.6251 - val_mae: 4.6095\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 48.8979 - mae: 4.9264 - val_loss: 38.4943 - val_mae: 4.6000\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 48.7534 - mae: 4.9181 - val_loss: 38.3642 - val_mae: 4.5915\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 48.6079 - mae: 4.9111 - val_loss: 38.2331 - val_mae: 4.5827\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 48.4616 - mae: 4.9038 - val_loss: 38.1009 - val_mae: 4.5739\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 48.3143 - mae: 4.8962 - val_loss: 37.9671 - val_mae: 4.5648\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 48.1661 - mae: 4.8881 - val_loss: 37.8319 - val_mae: 4.5553\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 48.0170 - mae: 4.8795 - val_loss: 37.6956 - val_mae: 4.5453\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 47.8672 - mae: 4.8703 - val_loss: 37.5584 - val_mae: 4.5353\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 47.7165 - mae: 4.8610 - val_loss: 37.4193 - val_mae: 4.5245\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 47.5650 - mae: 4.8507 - val_loss: 37.2787 - val_mae: 4.5134\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 47.4126 - mae: 4.8400 - val_loss: 37.1375 - val_mae: 4.5023\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 47.2596 - mae: 4.8293 - val_loss: 36.9976 - val_mae: 4.4923\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 47.1059 - mae: 4.8203 - val_loss: 36.8586 - val_mae: 4.4829\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 46.9514 - mae: 4.8123 - val_loss: 36.7193 - val_mae: 4.4735\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 46.7962 - mae: 4.8045 - val_loss: 36.5793 - val_mae: 4.4638\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 46.6405 - mae: 4.7965 - val_loss: 36.4366 - val_mae: 4.4530\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 46.4841 - mae: 4.7870 - val_loss: 36.2915 - val_mae: 4.4412\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 46.3271 - mae: 4.7763 - val_loss: 36.1464 - val_mae: 4.4296\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 46.1695 - mae: 4.7659 - val_loss: 36.0017 - val_mae: 4.4184\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 46.0115 - mae: 4.7565 - val_loss: 35.8577 - val_mae: 4.4078\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 45.8531 - mae: 4.7483 - val_loss: 35.7131 - val_mae: 4.3977\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 45.6943 - mae: 4.7402 - val_loss: 35.5659 - val_mae: 4.3872\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 45.5351 - mae: 4.7309 - val_loss: 35.4182 - val_mae: 4.3768\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 45.3756 - mae: 4.7216 - val_loss: 35.2702 - val_mae: 4.3666\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 45.2156 - mae: 4.7124 - val_loss: 35.1224 - val_mae: 4.3566\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 45.0543 - mae: 4.7036 - val_loss: 34.9753 - val_mae: 4.3470\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 44.8931 - mae: 4.6955 - val_loss: 34.8290 - val_mae: 4.3375\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 44.7317 - mae: 4.6876 - val_loss: 34.6828 - val_mae: 4.3278\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 44.5701 - mae: 4.6793 - val_loss: 34.5363 - val_mae: 4.3175\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 44.4084 - mae: 4.6705 - val_loss: 34.3893 - val_mae: 4.3068\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 44.2467 - mae: 4.6611 - val_loss: 34.2415 - val_mae: 4.2952\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 44.0854 - mae: 4.6516 - val_loss: 34.0940 - val_mae: 4.2833\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 43.9241 - mae: 4.6420 - val_loss: 33.9478 - val_mae: 4.2717\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 43.7625 - mae: 4.6331 - val_loss: 33.8026 - val_mae: 4.2605\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 43.6010 - mae: 4.6247 - val_loss: 33.6588 - val_mae: 4.2500\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 43.4399 - mae: 4.6174 - val_loss: 33.5157 - val_mae: 4.2403\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 43.2789 - mae: 4.6105 - val_loss: 33.3714 - val_mae: 4.2303\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 43.1176 - mae: 4.6026 - val_loss: 33.2260 - val_mae: 4.2196\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 42.9568 - mae: 4.5939 - val_loss: 33.0800 - val_mae: 4.2086\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 42.7961 - mae: 4.5847 - val_loss: 32.9343 - val_mae: 4.1981\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 42.6353 - mae: 4.5757 - val_loss: 32.7900 - val_mae: 4.1883\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 42.4749 - mae: 4.5675 - val_loss: 32.6451 - val_mae: 4.1789\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 42.3147 - mae: 4.5596 - val_loss: 32.5011 - val_mae: 4.1699\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 42.1547 - mae: 4.5522 - val_loss: 32.3584 - val_mae: 4.1612\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 41.9954 - mae: 4.5453 - val_loss: 32.2151 - val_mae: 4.1527\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 41.8370 - mae: 4.5387 - val_loss: 32.0722 - val_mae: 4.1449\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 41.6794 - mae: 4.5329 - val_loss: 31.9289 - val_mae: 4.1371\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 41.5222 - mae: 4.5272 - val_loss: 31.7848 - val_mae: 4.1288\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 41.3656 - mae: 4.5211 - val_loss: 31.6389 - val_mae: 4.1193\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 41.2095 - mae: 4.5137 - val_loss: 31.4915 - val_mae: 4.1089\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 41.0540 - mae: 4.5053 - val_loss: 31.3439 - val_mae: 4.0980\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 40.8990 - mae: 4.4970 - val_loss: 31.1975 - val_mae: 4.0879\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 40.7448 - mae: 4.4892 - val_loss: 31.0535 - val_mae: 4.0791\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 40.5912 - mae: 4.4828 - val_loss: 30.9118 - val_mae: 4.0709\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 40.4384 - mae: 4.4772 - val_loss: 30.7701 - val_mae: 4.0629\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 40.2867 - mae: 4.4713 - val_loss: 30.6279 - val_mae: 4.0546\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 40.1360 - mae: 4.4645 - val_loss: 30.4843 - val_mae: 4.0452\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 39.9861 - mae: 4.4565 - val_loss: 30.3419 - val_mae: 4.0360\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 39.8372 - mae: 4.4485 - val_loss: 30.2020 - val_mae: 4.0273\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 39.6893 - mae: 4.4413 - val_loss: 30.0660 - val_mae: 4.0202\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 39.5424 - mae: 4.4360 - val_loss: 29.9316 - val_mae: 4.0133\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 39.3968 - mae: 4.4311 - val_loss: 29.7957 - val_mae: 4.0046\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 39.2519 - mae: 4.4239 - val_loss: 29.6586 - val_mae: 3.9942\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 39.1081 - mae: 4.4149 - val_loss: 29.5241 - val_mae: 3.9845\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 38.9655 - mae: 4.4074 - val_loss: 29.3942 - val_mae: 3.9761\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 38.8238 - mae: 4.4017 - val_loss: 29.2662 - val_mae: 3.9678\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 38.6829 - mae: 4.3960 - val_loss: 29.1395 - val_mae: 3.9597\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 38.5429 - mae: 4.3900 - val_loss: 29.0154 - val_mae: 3.9529\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 38.4039 - mae: 4.3847 - val_loss: 28.8924 - val_mae: 3.9463\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 38.2658 - mae: 4.3794 - val_loss: 28.7696 - val_mae: 3.9391\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 38.1288 - mae: 4.3736 - val_loss: 28.6465 - val_mae: 3.9310\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37.9927 - mae: 4.3671 - val_loss: 28.5244 - val_mae: 3.9230\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37.8582 - mae: 4.3606 - val_loss: 28.4042 - val_mae: 3.9158\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 37.7252 - mae: 4.3549 - val_loss: 28.2849 - val_mae: 3.9088\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 37.5925 - mae: 4.3495 - val_loss: 28.1669 - val_mae: 3.9022\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 37.4618 - mae: 4.3446 - val_loss: 28.0496 - val_mae: 3.8956\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37.3329 - mae: 4.3395 - val_loss: 27.9327 - val_mae: 3.8889\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 37.2051 - mae: 4.3341 - val_loss: 27.8153 - val_mae: 3.8818\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 37.0782 - mae: 4.3282 - val_loss: 27.6976 - val_mae: 3.8744\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 36.9526 - mae: 4.3219 - val_loss: 27.5810 - val_mae: 3.8673\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 36.8281 - mae: 4.3160 - val_loss: 27.4655 - val_mae: 3.8607\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 36.7041 - mae: 4.3105 - val_loss: 27.3521 - val_mae: 3.8536\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 36.5809 - mae: 4.3046 - val_loss: 27.2412 - val_mae: 3.8462\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 36.4583 - mae: 4.2983 - val_loss: 27.1301 - val_mae: 3.8389\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 36.3366 - mae: 4.2928 - val_loss: 27.0206 - val_mae: 3.8320\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 36.2166 - mae: 4.2880 - val_loss: 26.8967 - val_mae: 3.8188\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 36.0987 - mae: 4.2768 - val_loss: 26.7713 - val_mae: 3.8048\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 35.9828 - mae: 4.2649 - val_loss: 26.6558 - val_mae: 3.7963\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 35.8680 - mae: 4.2584 - val_loss: 26.5542 - val_mae: 3.7952\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 35.7526 - mae: 4.2588 - val_loss: 26.4541 - val_mae: 3.7936\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 35.6384 - mae: 4.2588 - val_loss: 26.3417 - val_mae: 3.7856\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 35.5238 - mae: 4.2523 - val_loss: 26.2234 - val_mae: 3.7738\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 35.4093 - mae: 4.2418 - val_loss: 26.1106 - val_mae: 3.7632\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 35.2956 - mae: 4.2328 - val_loss: 26.0081 - val_mae: 3.7566\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 35.1819 - mae: 4.2281 - val_loss: 25.9129 - val_mae: 3.7522\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 35.0675 - mae: 4.2255 - val_loss: 25.8219 - val_mae: 3.7503\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 34.9582 - mae: 4.2256 - val_loss: 25.7223 - val_mae: 3.7450\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 34.8488 - mae: 4.2222 - val_loss: 25.6092 - val_mae: 3.7343\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 34.7387 - mae: 4.2132 - val_loss: 25.4921 - val_mae: 3.7217\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 34.6295 - mae: 4.2021 - val_loss: 25.3873 - val_mae: 3.7141\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 34.5213 - mae: 4.1960 - val_loss: 25.2976 - val_mae: 3.7137\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 34.4128 - mae: 4.1974 - val_loss: 25.2071 - val_mae: 3.7127\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 34.3071 - mae: 4.1984 - val_loss: 25.0938 - val_mae: 3.6998\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 34.1985 - mae: 4.1872 - val_loss: 24.9824 - val_mae: 3.6846\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 34.0920 - mae: 4.1734 - val_loss: 24.8881 - val_mae: 3.6795\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 33.9851 - mae: 4.1695 - val_loss: 24.8048 - val_mae: 3.6819\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 33.8778 - mae: 4.1734 - val_loss: 24.7152 - val_mae: 3.6787\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 33.7706 - mae: 4.1715 - val_loss: 24.6128 - val_mae: 3.6669\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 33.6609 - mae: 4.1607 - val_loss: 24.5095 - val_mae: 3.6530\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 33.5548 - mae: 4.1481 - val_loss: 24.4103 - val_mae: 3.6447\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 33.4491 - mae: 4.1411 - val_loss: 24.3166 - val_mae: 3.6432\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 33.3447 - mae: 4.1413 - val_loss: 24.2236 - val_mae: 3.6420\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 33.2443 - mae: 4.1423 - val_loss: 24.1217 - val_mae: 3.6334\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 33.1432 - mae: 4.1356 - val_loss: 24.0113 - val_mae: 3.6184\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 33.0426 - mae: 4.1225 - val_loss: 23.9141 - val_mae: 3.6154\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 32.9389 - mae: 4.1211 - val_loss: 23.8238 - val_mae: 3.6172\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 32.8380 - mae: 4.1249 - val_loss: 23.7106 - val_mae: 3.6040\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 32.7337 - mae: 4.1139 - val_loss: 23.5893 - val_mae: 3.5841\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 32.6341 - mae: 4.0961 - val_loss: 23.4911 - val_mae: 3.5797\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 32.5320 - mae: 4.0940 - val_loss: 23.4098 - val_mae: 3.5837\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 32.4332 - mae: 4.1001 - val_loss: 23.3113 - val_mae: 3.5725\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 32.3314 - mae: 4.0907 - val_loss: 23.2013 - val_mae: 3.5505\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 32.2320 - mae: 4.0711 - val_loss: 23.1136 - val_mae: 3.5456\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 32.1323 - mae: 4.0686 - val_loss: 23.0334 - val_mae: 3.5463\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 32.0342 - mae: 4.0719 - val_loss: 22.9417 - val_mae: 3.5391\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 31.9366 - mae: 4.0676 - val_loss: 22.8392 - val_mae: 3.5233\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 31.8376 - mae: 4.0544 - val_loss: 22.7412 - val_mae: 3.5106\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 31.7393 - mae: 4.0445 - val_loss: 22.6515 - val_mae: 3.5042\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 31.6390 - mae: 4.0407 - val_loss: 22.5673 - val_mae: 3.4999\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 31.5389 - mae: 4.0387 - val_loss: 22.4825 - val_mae: 3.4923\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 31.4393 - mae: 4.0327 - val_loss: 22.3960 - val_mae: 3.4803\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 31.3388 - mae: 4.0210 - val_loss: 22.3137 - val_mae: 3.4702\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 31.2397 - mae: 4.0115 - val_loss: 22.2412 - val_mae: 3.4661\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 31.1410 - mae: 4.0074 - val_loss: 22.1688 - val_mae: 3.4626\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 31.0439 - mae: 4.0031 - val_loss: 22.0902 - val_mae: 3.4580\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 30.9470 - mae: 3.9978 - val_loss: 22.0100 - val_mae: 3.4510\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 30.8511 - mae: 3.9901 - val_loss: 21.9316 - val_mae: 3.4423\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 30.7560 - mae: 3.9801 - val_loss: 21.8552 - val_mae: 3.4349\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 30.6630 - mae: 3.9713 - val_loss: 21.7856 - val_mae: 3.4396\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 30.5705 - mae: 3.9743 - val_loss: 21.7134 - val_mae: 3.4334\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 30.4793 - mae: 3.9673 - val_loss: 21.6387 - val_mae: 3.4221\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 30.3885 - mae: 3.9553 - val_loss: 21.5713 - val_mae: 3.4220\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 30.2981 - mae: 3.9528 - val_loss: 21.5062 - val_mae: 3.4189\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 30.2114 - mae: 3.9476 - val_loss: 21.4338 - val_mae: 3.4109\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 30.1281 - mae: 3.9388 - val_loss: 21.3586 - val_mae: 3.4033\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 30.0477 - mae: 3.9320 - val_loss: 21.2792 - val_mae: 3.4016\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 29.9665 - mae: 3.9316 - val_loss: 21.2010 - val_mae: 3.3978\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 29.8868 - mae: 3.9301 - val_loss: 21.1247 - val_mae: 3.3887\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 29.8074 - mae: 3.9233 - val_loss: 21.0504 - val_mae: 3.3799\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 29.7305 - mae: 3.9174 - val_loss: 20.9838 - val_mae: 3.3836\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 29.6545 - mae: 3.9238 - val_loss: 20.9222 - val_mae: 3.3749\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 29.5790 - mae: 3.9172 - val_loss: 20.8710 - val_mae: 3.3585\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 29.5071 - mae: 3.9013 - val_loss: 20.8256 - val_mae: 3.3607\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 29.4324 - mae: 3.9028 - val_loss: 20.7865 - val_mae: 3.3723\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 29.3636 - mae: 3.9133 - val_loss: 20.7361 - val_mae: 3.3623\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 29.2903 - mae: 3.9023 - val_loss: 20.6831 - val_mae: 3.3437\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 29.2238 - mae: 3.8843 - val_loss: 20.6199 - val_mae: 3.3481\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 29.1485 - mae: 3.8899 - val_loss: 20.5524 - val_mae: 3.3505\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 29.0812 - mae: 3.8968 - val_loss: 20.4877 - val_mae: 3.3356\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 29.0132 - mae: 3.8841 - val_loss: 20.4274 - val_mae: 3.3216\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 28.9497 - mae: 3.8714 - val_loss: 20.3638 - val_mae: 3.3275\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 28.8822 - mae: 3.8800 - val_loss: 20.3048 - val_mae: 3.3265\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 28.8190 - mae: 3.8809 - val_loss: 20.2502 - val_mae: 3.3103\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 28.7548 - mae: 3.8646 - val_loss: 20.1974 - val_mae: 3.2999\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 28.6976 - mae: 3.8551 - val_loss: 20.1356 - val_mae: 3.3120\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 28.6343 - mae: 3.8715 - val_loss: 20.0746 - val_mae: 3.3069\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 28.5743 - mae: 3.8697 - val_loss: 20.0146 - val_mae: 3.2848\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 28.5134 - mae: 3.8505 - val_loss: 19.9556 - val_mae: 3.2803\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 28.4543 - mae: 3.8502 - val_loss: 19.9004 - val_mae: 3.2872\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 28.3983 - mae: 3.8609 - val_loss: 19.8586 - val_mae: 3.2752\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 28.3345 - mae: 3.8497 - val_loss: 19.8205 - val_mae: 3.2600\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 28.2769 - mae: 3.8353 - val_loss: 19.7591 - val_mae: 3.2674\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 28.2094 - mae: 3.8463 - val_loss: 19.6997 - val_mae: 3.2673\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 28.1488 - mae: 3.8498 - val_loss: 19.6434 - val_mae: 3.2484\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 28.0883 - mae: 3.8355 - val_loss: 19.5788 - val_mae: 3.2450\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 28.0323 - mae: 3.8362 - val_loss: 19.5104 - val_mae: 3.2435\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 27.9784 - mae: 3.8382 - val_loss: 19.4431 - val_mae: 3.2371\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 27.9250 - mae: 3.8345 - val_loss: 19.3749 - val_mae: 3.2290\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 27.8720 - mae: 3.8289 - val_loss: 19.3044 - val_mae: 3.2248\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 27.8201 - mae: 3.8275 - val_loss: 19.2370 - val_mae: 3.2223\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 27.7692 - mae: 3.8274 - val_loss: 19.1771 - val_mae: 3.2164\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 27.7204 - mae: 3.8235 - val_loss: 19.1275 - val_mae: 3.2090\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 27.6741 - mae: 3.8174 - val_loss: 19.0864 - val_mae: 3.2133\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 27.6268 - mae: 3.8219 - val_loss: 19.0552 - val_mae: 3.2093\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 27.5803 - mae: 3.8176 - val_loss: 19.0325 - val_mae: 3.2073\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 27.5332 - mae: 3.8147 - val_loss: 19.0193 - val_mae: 3.2076\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 27.4861 - mae: 3.8130 - val_loss: 19.0120 - val_mae: 3.2090\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 27.4413 - mae: 3.8121 - val_loss: 19.0002 - val_mae: 3.2103\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 27.3959 - mae: 3.8129 - val_loss: 18.9840 - val_mae: 3.1980\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 27.3503 - mae: 3.8013 - val_loss: 18.9647 - val_mae: 3.1982\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 27.3054 - mae: 3.8021 - val_loss: 18.9399 - val_mae: 3.2049\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 27.2644 - mae: 3.8098 - val_loss: 18.9275 - val_mae: 3.1923\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 27.2188 - mae: 3.7939 - val_loss: 18.9107 - val_mae: 3.1910\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 27.1746 - mae: 3.7890 - val_loss: 18.8906 - val_mae: 3.2057\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 27.1312 - mae: 3.7984 - val_loss: 18.8694 - val_mae: 3.2009\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 27.0892 - mae: 3.7897 - val_loss: 18.8445 - val_mae: 3.1993\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 27.0487 - mae: 3.7846 - val_loss: 18.8104 - val_mae: 3.2062\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 27.0074 - mae: 3.7904 - val_loss: 18.7806 - val_mae: 3.1934\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 26.9631 - mae: 3.7758 - val_loss: 18.7516 - val_mae: 3.1915\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 26.9207 - mae: 3.7720 - val_loss: 18.7309 - val_mae: 3.2009\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 26.8750 - mae: 3.7764 - val_loss: 18.7174 - val_mae: 3.2075\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 26.8306 - mae: 3.7769 - val_loss: 18.7090 - val_mae: 3.2067\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 26.7869 - mae: 3.7699 - val_loss: 18.6979 - val_mae: 3.2083\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 26.7426 - mae: 3.7671 - val_loss: 18.6847 - val_mae: 3.2126\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 26.6977 - mae: 3.7687 - val_loss: 18.6722 - val_mae: 3.2025\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 26.6552 - mae: 3.7568 - val_loss: 18.6558 - val_mae: 3.2060\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 26.6122 - mae: 3.7583 - val_loss: 18.6410 - val_mae: 3.2160\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 26.5727 - mae: 3.7667 - val_loss: 18.6285 - val_mae: 3.2062\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 26.5268 - mae: 3.7528 - val_loss: 18.6201 - val_mae: 3.1956\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 26.4895 - mae: 3.7374 - val_loss: 18.5918 - val_mae: 3.2177\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 26.4448 - mae: 3.7601 - val_loss: 18.5672 - val_mae: 3.2153\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 26.4020 - mae: 3.7549 - val_loss: 18.5474 - val_mae: 3.1953\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 26.3621 - mae: 3.7312 - val_loss: 18.5121 - val_mae: 3.2063\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 26.3171 - mae: 3.7435 - val_loss: 18.4891 - val_mae: 3.2073\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 26.2769 - mae: 3.7437 - val_loss: 18.4787 - val_mae: 3.1958\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 26.2353 - mae: 3.7275 - val_loss: 18.4673 - val_mae: 3.2026\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 26.1930 - mae: 3.7313 - val_loss: 18.4606 - val_mae: 3.2082\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 26.1552 - mae: 3.7345 - val_loss: 18.4523 - val_mae: 3.2027\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 26.1148 - mae: 3.7265 - val_loss: 18.4375 - val_mae: 3.2062\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 26.0763 - mae: 3.7301 - val_loss: 18.4275 - val_mae: 3.1988\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 26.0385 - mae: 3.7195 - val_loss: 18.4172 - val_mae: 3.2034\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 25.9996 - mae: 3.7206 - val_loss: 18.4074 - val_mae: 3.2135\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 25.9653 - mae: 3.7282 - val_loss: 18.3910 - val_mae: 3.2028\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 25.9285 - mae: 3.7136 - val_loss: 18.3708 - val_mae: 3.2023\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 25.8941 - mae: 3.7121 - val_loss: 18.3496 - val_mae: 3.2088\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 25.8605 - mae: 3.7190 - val_loss: 18.3289 - val_mae: 3.1978\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 25.8262 - mae: 3.7067 - val_loss: 18.3119 - val_mae: 3.1960\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 25.7933 - mae: 3.7034 - val_loss: 18.2865 - val_mae: 3.2062\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 25.7609 - mae: 3.7135 - val_loss: 18.2643 - val_mae: 3.1968\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 25.7261 - mae: 3.7023 - val_loss: 18.2375 - val_mae: 3.1935\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 25.6943 - mae: 3.6987 - val_loss: 18.2032 - val_mae: 3.2006\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 25.6643 - mae: 3.7073 - val_loss: 18.1746 - val_mae: 3.1916\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 25.6313 - mae: 3.6974 - val_loss: 18.1524 - val_mae: 3.1822\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 25.6034 - mae: 3.6865 - val_loss: 18.1190 - val_mae: 3.1965\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 25.5709 - mae: 3.7009 - val_loss: 18.0928 - val_mae: 3.1939\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 25.5395 - mae: 3.6975 - val_loss: 18.0733 - val_mae: 3.1783\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 25.5097 - mae: 3.6793 - val_loss: 18.0441 - val_mae: 3.1848\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 25.4755 - mae: 3.6852 - val_loss: 18.0180 - val_mae: 3.1913\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 25.4454 - mae: 3.6903 - val_loss: 17.9942 - val_mae: 3.1834\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 25.4126 - mae: 3.6799 - val_loss: 17.9699 - val_mae: 3.1759\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 25.3830 - mae: 3.6696 - val_loss: 17.9313 - val_mae: 3.1877\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 25.3498 - mae: 3.6821 - val_loss: 17.8952 - val_mae: 3.1835\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 25.3175 - mae: 3.6766 - val_loss: 17.8575 - val_mae: 3.1718\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 25.2884 - mae: 3.6637 - val_loss: 17.8082 - val_mae: 3.1771\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 25.2552 - mae: 3.6713 - val_loss: 17.7578 - val_mae: 3.1776\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 25.2254 - mae: 3.6749 - val_loss: 17.7069 - val_mae: 3.1650\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 25.1923 - mae: 3.6644 - val_loss: 17.6618 - val_mae: 3.1593\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 25.1597 - mae: 3.6617 - val_loss: 17.6261 - val_mae: 3.1602\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 25.1287 - mae: 3.6664 - val_loss: 17.6197 - val_mae: 3.1541\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 25.0934 - mae: 3.6585 - val_loss: 17.6226 - val_mae: 3.1542\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 25.0590 - mae: 3.6543 - val_loss: 17.6329 - val_mae: 3.1655\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 25.0223 - mae: 3.6598 - val_loss: 17.6464 - val_mae: 3.1739\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 24.9908 - mae: 3.6625 - val_loss: 17.6510 - val_mae: 3.1640\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 24.9581 - mae: 3.6445 - val_loss: 17.6470 - val_mae: 3.1670\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 24.9214 - mae: 3.6438 - val_loss: 17.6388 - val_mae: 3.1763\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 24.8805 - mae: 3.6522 - val_loss: 17.6321 - val_mae: 3.1724\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 24.8344 - mae: 3.6439 - val_loss: 17.6387 - val_mae: 3.1703\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 24.7953 - mae: 3.6343 - val_loss: 17.6445 - val_mae: 3.1793\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 24.7547 - mae: 3.6390 - val_loss: 17.6571 - val_mae: 3.1869\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 24.7078 - mae: 3.6396 - val_loss: 17.6755 - val_mae: 3.1860\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 24.6563 - mae: 3.6267 - val_loss: 17.6746 - val_mae: 3.1912\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 24.6063 - mae: 3.6220 - val_loss: 17.6620 - val_mae: 3.2049\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 24.5584 - mae: 3.6296 - val_loss: 17.6433 - val_mae: 3.2091\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 24.5124 - mae: 3.6271 - val_loss: 17.6231 - val_mae: 3.2028\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 24.4615 - mae: 3.6126 - val_loss: 17.6050 - val_mae: 3.2064\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 24.4027 - mae: 3.6088 - val_loss: 17.5997 - val_mae: 3.2182\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 24.3440 - mae: 3.6117 - val_loss: 17.6054 - val_mae: 3.2253\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 24.2856 - mae: 3.6065 - val_loss: 17.6248 - val_mae: 3.2252\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 24.2321 - mae: 3.5931 - val_loss: 17.6409 - val_mae: 3.2351\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 24.1790 - mae: 3.5924 - val_loss: 17.6509 - val_mae: 3.2445\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 24.1316 - mae: 3.5942 - val_loss: 17.6427 - val_mae: 3.2414\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 24.0868 - mae: 3.5877 - val_loss: 17.6137 - val_mae: 3.2319\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 24.0380 - mae: 3.5765 - val_loss: 17.5658 - val_mae: 3.2288\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 23.9871 - mae: 3.5740 - val_loss: 17.5005 - val_mae: 3.2284\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 23.9360 - mae: 3.5762 - val_loss: 17.4209 - val_mae: 3.2193\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 23.8838 - mae: 3.5703 - val_loss: 17.3345 - val_mae: 3.2043\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 23.8350 - mae: 3.5592 - val_loss: 17.2355 - val_mae: 3.2006\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 23.7814 - mae: 3.5587 - val_loss: 17.1294 - val_mae: 3.1934\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 23.7284 - mae: 3.5550 - val_loss: 17.0164 - val_mae: 3.1802\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 23.6759 - mae: 3.5466 - val_loss: 16.9039 - val_mae: 3.1673\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 23.6278 - mae: 3.5392 - val_loss: 16.7777 - val_mae: 3.1657\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 23.5768 - mae: 3.5434 - val_loss: 16.6593 - val_mae: 3.1570\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 23.5279 - mae: 3.5405 - val_loss: 16.5549 - val_mae: 3.1397\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 23.4772 - mae: 3.5287 - val_loss: 16.4682 - val_mae: 3.1313\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 23.4266 - mae: 3.5214 - val_loss: 16.3847 - val_mae: 3.1391\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 23.3765 - mae: 3.5294 - val_loss: 16.3166 - val_mae: 3.1290\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 23.3216 - mae: 3.5198 - val_loss: 16.2653 - val_mae: 3.1164\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 23.2730 - mae: 3.5059 - val_loss: 16.2130 - val_mae: 3.1218\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 23.2136 - mae: 3.5104 - val_loss: 16.1775 - val_mae: 3.1272\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 23.1646 - mae: 3.5131 - val_loss: 16.1625 - val_mae: 3.1132\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 23.1085 - mae: 3.4923 - val_loss: 16.1418 - val_mae: 3.1174\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 23.0518 - mae: 3.4902 - val_loss: 16.1290 - val_mae: 3.1312\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 23.0011 - mae: 3.4987 - val_loss: 16.1250 - val_mae: 3.1243\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 22.9411 - mae: 3.4836 - val_loss: 16.1177 - val_mae: 3.1161\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 22.8903 - mae: 3.4691 - val_loss: 16.0718 - val_mae: 3.1196\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 22.8364 - mae: 3.4737 - val_loss: 16.0258 - val_mae: 3.1161\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 22.7831 - mae: 3.4702 - val_loss: 15.9719 - val_mae: 3.1011\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 22.7294 - mae: 3.4561 - val_loss: 15.9036 - val_mae: 3.0933\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 22.6764 - mae: 3.4505 - val_loss: 15.8242 - val_mae: 3.0950\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 22.6235 - mae: 3.4544 - val_loss: 15.7457 - val_mae: 3.0835\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 22.5710 - mae: 3.4450 - val_loss: 15.6621 - val_mae: 3.0684\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 22.5252 - mae: 3.4338 - val_loss: 15.5480 - val_mae: 3.0644\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 22.4747 - mae: 3.4365 - val_loss: 15.4420 - val_mae: 3.0553\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 22.4284 - mae: 3.4340 - val_loss: 15.3402 - val_mae: 3.0372\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 22.3807 - mae: 3.4229 - val_loss: 15.2475 - val_mae: 3.0249\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 22.3353 - mae: 3.4156 - val_loss: 15.1673 - val_mae: 3.0227\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 22.2906 - mae: 3.4148 - val_loss: 15.0988 - val_mae: 3.0193\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 22.2476 - mae: 3.4121 - val_loss: 15.0290 - val_mae: 3.0103\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 22.2048 - mae: 3.4053 - val_loss: 14.9597 - val_mae: 3.0007\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 22.1586 - mae: 3.3995 - val_loss: 14.9032 - val_mae: 2.9914\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 22.1163 - mae: 3.3946 - val_loss: 14.8439 - val_mae: 2.9838\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 22.0770 - mae: 3.3916 - val_loss: 14.7965 - val_mae: 2.9783\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 22.0360 - mae: 3.3877 - val_loss: 14.7591 - val_mae: 2.9769\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 21.9948 - mae: 3.3853 - val_loss: 14.7231 - val_mae: 2.9736\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 21.9554 - mae: 3.3817 - val_loss: 14.6803 - val_mae: 2.9671\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 21.9165 - mae: 3.3770 - val_loss: 14.6354 - val_mae: 2.9576\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 21.8773 - mae: 3.3703 - val_loss: 14.5888 - val_mae: 2.9576\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 21.8372 - mae: 3.3688 - val_loss: 14.5381 - val_mae: 2.9547\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 21.7979 - mae: 3.3658 - val_loss: 14.4844 - val_mae: 2.9482\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 21.7587 - mae: 3.3617 - val_loss: 14.4289 - val_mae: 2.9407\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 21.7199 - mae: 3.3579 - val_loss: 14.3796 - val_mae: 2.9364\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 21.6811 - mae: 3.3551 - val_loss: 14.3351 - val_mae: 2.9321\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 21.6430 - mae: 3.3517 - val_loss: 14.2969 - val_mae: 2.9313\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 21.6044 - mae: 3.3497 - val_loss: 14.2545 - val_mae: 2.9235\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 21.5670 - mae: 3.3445 - val_loss: 14.2237 - val_mae: 2.9221\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 21.5313 - mae: 3.3425 - val_loss: 14.1970 - val_mae: 2.9220\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 21.4967 - mae: 3.3412 - val_loss: 14.1672 - val_mae: 2.9149\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 21.4627 - mae: 3.3373 - val_loss: 14.1420 - val_mae: 2.9102\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 21.4294 - mae: 3.3342 - val_loss: 14.1226 - val_mae: 2.9119\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 21.3953 - mae: 3.3332 - val_loss: 14.1002 - val_mae: 2.9097\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 21.3610 - mae: 3.3305 - val_loss: 14.0742 - val_mae: 2.9061\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 21.3292 - mae: 3.3272 - val_loss: 14.0544 - val_mae: 2.9126\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 21.2974 - mae: 3.3290 - val_loss: 14.0123 - val_mae: 2.8997\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 21.2628 - mae: 3.3219 - val_loss: 13.9763 - val_mae: 2.8927\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 21.2333 - mae: 3.3168 - val_loss: 13.9671 - val_mae: 2.9109\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 21.2007 - mae: 3.3227 - val_loss: 13.9212 - val_mae: 2.9019\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 21.1672 - mae: 3.3167 - val_loss: 13.8685 - val_mae: 2.8856\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 21.1399 - mae: 3.3092 - val_loss: 13.8519 - val_mae: 2.9001\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 21.1070 - mae: 3.3143 - val_loss: 13.8123 - val_mae: 2.8906\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 21.0741 - mae: 3.3098 - val_loss: 13.7729 - val_mae: 2.8734\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 21.0478 - mae: 3.3021 - val_loss: 13.7721 - val_mae: 2.8885\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 21.0140 - mae: 3.3060 - val_loss: 13.7628 - val_mae: 2.8858\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 20.9816 - mae: 3.3016 - val_loss: 13.7513 - val_mae: 2.8775\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 20.9518 - mae: 3.2963 - val_loss: 13.7623 - val_mae: 2.8873\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 20.9230 - mae: 3.2986 - val_loss: 13.7668 - val_mae: 2.8900\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 20.8920 - mae: 3.2975 - val_loss: 13.7509 - val_mae: 2.8778\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 20.8677 - mae: 3.2897 - val_loss: 13.7539 - val_mae: 2.8893\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 20.8355 - mae: 3.2915 - val_loss: 13.7324 - val_mae: 2.8892\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 20.8031 - mae: 3.2906 - val_loss: 13.6852 - val_mae: 2.8720\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 20.7732 - mae: 3.2824 - val_loss: 13.6580 - val_mae: 2.8680\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 20.7465 - mae: 3.2789 - val_loss: 13.6560 - val_mae: 2.8820\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 20.7167 - mae: 3.2821 - val_loss: 13.6300 - val_mae: 2.8747\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 20.6881 - mae: 3.2758 - val_loss: 13.6117 - val_mae: 2.8742\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 20.6619 - mae: 3.2745 - val_loss: 13.5937 - val_mae: 2.8743\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 20.6316 - mae: 3.2739 - val_loss: 13.5661 - val_mae: 2.8637\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 20.6025 - mae: 3.2689 - val_loss: 13.5535 - val_mae: 2.8646\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 20.5746 - mae: 3.2672 - val_loss: 13.5467 - val_mae: 2.8704\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 20.5453 - mae: 3.2665 - val_loss: 13.5164 - val_mae: 2.8611\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 20.5177 - mae: 3.2603 - val_loss: 13.4923 - val_mae: 2.8583\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 20.4903 - mae: 3.2579 - val_loss: 13.4725 - val_mae: 2.8568\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 20.4623 - mae: 3.2576 - val_loss: 13.4503 - val_mae: 2.8499\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 20.4385 - mae: 3.2542 - val_loss: 13.4363 - val_mae: 2.8554\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 20.4103 - mae: 3.2547 - val_loss: 13.4139 - val_mae: 2.8523\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 20.3881 - mae: 3.2506 - val_loss: 13.3924 - val_mae: 2.8535\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 20.3570 - mae: 3.2496 - val_loss: 13.3594 - val_mae: 2.8479\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 20.3372 - mae: 3.2491 - val_loss: 13.3065 - val_mae: 2.8298\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 20.3074 - mae: 3.2428 - val_loss: 13.2822 - val_mae: 2.8337\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 20.2826 - mae: 3.2440 - val_loss: 13.2700 - val_mae: 2.8387\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 20.2606 - mae: 3.2460 - val_loss: 13.2442 - val_mae: 2.8236\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 20.2320 - mae: 3.2373 - val_loss: 13.2478 - val_mae: 2.8343\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 20.2077 - mae: 3.2412 - val_loss: 13.2349 - val_mae: 2.8318\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 20.1799 - mae: 3.2369 - val_loss: 13.2153 - val_mae: 2.8294\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 20.1584 - mae: 3.2362 - val_loss: 13.1932 - val_mae: 2.8229\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 20.1328 - mae: 3.2331 - val_loss: 13.1783 - val_mae: 2.8203\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 20.1122 - mae: 3.2319 - val_loss: 13.1704 - val_mae: 2.8245\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 20.0899 - mae: 3.2335 - val_loss: 13.1403 - val_mae: 2.8148\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 20.0660 - mae: 3.2290 - val_loss: 13.1238 - val_mae: 2.8107\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 20.0447 - mae: 3.2256 - val_loss: 13.1321 - val_mae: 2.8239\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 20.0240 - mae: 3.2291 - val_loss: 13.1025 - val_mae: 2.8120\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 20.0000 - mae: 3.2232 - val_loss: 13.0831 - val_mae: 2.8099\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 19.9760 - mae: 3.2226 - val_loss: 13.0727 - val_mae: 2.8135\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 19.9613 - mae: 3.2260 - val_loss: 13.0331 - val_mae: 2.7966\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 19.9361 - mae: 3.2173 - val_loss: 13.0383 - val_mae: 2.8015\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 19.9115 - mae: 3.2165 - val_loss: 13.0710 - val_mae: 2.8180\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 19.8981 - mae: 3.2214 - val_loss: 13.0313 - val_mae: 2.7988\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 19.8744 - mae: 3.2094 - val_loss: 13.0273 - val_mae: 2.8014\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 19.8487 - mae: 3.2094 - val_loss: 13.0467 - val_mae: 2.8157\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 19.8311 - mae: 3.2153 - val_loss: 13.0038 - val_mae: 2.7964\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 19.8052 - mae: 3.2063 - val_loss: 12.9911 - val_mae: 2.7939\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 19.7825 - mae: 3.2051 - val_loss: 12.9976 - val_mae: 2.8038\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 19.7632 - mae: 3.2096 - val_loss: 12.9565 - val_mae: 2.7868\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 19.7398 - mae: 3.2010 - val_loss: 12.9440 - val_mae: 2.7894\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 19.7156 - mae: 3.2025 - val_loss: 12.9427 - val_mae: 2.7974\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 19.6999 - mae: 3.2064 - val_loss: 12.8879 - val_mae: 2.7790\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 19.6772 - mae: 3.1942 - val_loss: 12.8772 - val_mae: 2.7819\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 19.6528 - mae: 3.1950 - val_loss: 12.8894 - val_mae: 2.7922\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 19.6372 - mae: 3.2005 - val_loss: 12.8493 - val_mae: 2.7769\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 19.6136 - mae: 3.1935 - val_loss: 12.8338 - val_mae: 2.7740\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 19.5931 - mae: 3.1920 - val_loss: 12.8427 - val_mae: 2.7811\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 19.5707 - mae: 3.1937 - val_loss: 12.8292 - val_mae: 2.7776\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 19.5502 - mae: 3.1899 - val_loss: 12.8135 - val_mae: 2.7721\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 19.5318 - mae: 3.1854 - val_loss: 12.8287 - val_mae: 2.7791\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 19.5099 - mae: 3.1882 - val_loss: 12.8301 - val_mae: 2.7810\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 19.4919 - mae: 3.1873 - val_loss: 12.7986 - val_mae: 2.7666\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 19.4784 - mae: 3.1780 - val_loss: 12.8262 - val_mae: 2.7802\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 19.4492 - mae: 3.1835 - val_loss: 12.8293 - val_mae: 2.7825\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 19.4334 - mae: 3.1844 - val_loss: 12.7816 - val_mae: 2.7664\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 19.4153 - mae: 3.1748 - val_loss: 12.7852 - val_mae: 2.7716\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 19.3896 - mae: 3.1760 - val_loss: 12.7905 - val_mae: 2.7757\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 19.3736 - mae: 3.1767 - val_loss: 12.7559 - val_mae: 2.7634\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 19.3545 - mae: 3.1689 - val_loss: 12.7705 - val_mae: 2.7701\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 19.3316 - mae: 3.1704 - val_loss: 12.7902 - val_mae: 2.7785\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 19.3162 - mae: 3.1721 - val_loss: 12.7517 - val_mae: 2.7645\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 19.2977 - mae: 3.1628 - val_loss: 12.7627 - val_mae: 2.7709\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 19.2736 - mae: 3.1637 - val_loss: 12.7785 - val_mae: 2.7777\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 19.2581 - mae: 3.1656 - val_loss: 12.7427 - val_mae: 2.7639\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 19.2392 - mae: 3.1575 - val_loss: 12.7474 - val_mae: 2.7680\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 19.2165 - mae: 3.1579 - val_loss: 12.7622 - val_mae: 2.7783\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 19.2049 - mae: 3.1608 - val_loss: 12.7033 - val_mae: 2.7598\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 19.1808 - mae: 3.1491 - val_loss: 12.6919 - val_mae: 2.7591\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 19.1599 - mae: 3.1472 - val_loss: 12.7257 - val_mae: 2.7763\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 19.1483 - mae: 3.1528 - val_loss: 12.6968 - val_mae: 2.7669\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 19.1264 - mae: 3.1368 - val_loss: 12.7233 - val_mae: 2.7830\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 19.1026 - mae: 3.1417 - val_loss: 12.7267 - val_mae: 2.7881\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 19.0862 - mae: 3.1457 - val_loss: 12.6438 - val_mae: 2.7577\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 19.0663 - mae: 3.1317 - val_loss: 12.6404 - val_mae: 2.7614\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 19.0391 - mae: 3.1379 - val_loss: 12.6378 - val_mae: 2.7659\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 19.0213 - mae: 3.1382 - val_loss: 12.6127 - val_mae: 2.7584\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 19.0027 - mae: 3.1300 - val_loss: 12.6322 - val_mae: 2.7667\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 18.9788 - mae: 3.1307 - val_loss: 12.6551 - val_mae: 2.7736\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 18.9608 - mae: 3.1320 - val_loss: 12.6466 - val_mae: 2.7707\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 18.9425 - mae: 3.1272 - val_loss: 12.6506 - val_mae: 2.7751\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 18.9227 - mae: 3.1277 - val_loss: 12.6431 - val_mae: 2.7755\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 18.9061 - mae: 3.1277 - val_loss: 12.6011 - val_mae: 2.7615\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 18.8858 - mae: 3.1204 - val_loss: 12.5953 - val_mae: 2.7608\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 18.8679 - mae: 3.1219 - val_loss: 12.6043 - val_mae: 2.7662\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 18.8500 - mae: 3.1241 - val_loss: 12.5883 - val_mae: 2.7630\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 18.8311 - mae: 3.1184 - val_loss: 12.6005 - val_mae: 2.7701\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 18.8127 - mae: 3.1183 - val_loss: 12.6032 - val_mae: 2.7703\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 18.7916 - mae: 3.1165 - val_loss: 12.5862 - val_mae: 2.7614\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 18.7768 - mae: 3.1113 - val_loss: 12.6043 - val_mae: 2.7679\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 18.7555 - mae: 3.1129 - val_loss: 12.5953 - val_mae: 2.7669\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 18.7332 - mae: 3.1094 - val_loss: 12.5863 - val_mae: 2.7643\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 18.7162 - mae: 3.1056 - val_loss: 12.5968 - val_mae: 2.7660\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 18.6937 - mae: 3.1058 - val_loss: 12.6079 - val_mae: 2.7693\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 18.6795 - mae: 3.1072 - val_loss: 12.5653 - val_mae: 2.7526\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 18.6712 - mae: 3.0971 - val_loss: 12.5966 - val_mae: 2.7697\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 18.6416 - mae: 3.1050 - val_loss: 12.5825 - val_mae: 2.7694\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 18.6211 - mae: 3.1016 - val_loss: 12.5425 - val_mae: 2.7557\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 18.6150 - mae: 3.0930 - val_loss: 12.5744 - val_mae: 2.7729\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 18.5915 - mae: 3.1020 - val_loss: 12.5240 - val_mae: 2.7601\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 18.5683 - mae: 3.0946 - val_loss: 12.5031 - val_mae: 2.7579\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 18.5508 - mae: 3.0930 - val_loss: 12.5031 - val_mae: 2.7596\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 18.5347 - mae: 3.0951 - val_loss: 12.4728 - val_mae: 2.7508\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 18.5215 - mae: 3.0898 - val_loss: 12.4882 - val_mae: 2.7599\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 18.5018 - mae: 3.0930 - val_loss: 12.4659 - val_mae: 2.7579\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 18.4847 - mae: 3.0892 - val_loss: 12.4333 - val_mae: 2.7479\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 18.4699 - mae: 3.0840 - val_loss: 12.4530 - val_mae: 2.7558\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 18.4545 - mae: 3.0878 - val_loss: 12.4259 - val_mae: 2.7472\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 18.4370 - mae: 3.0829 - val_loss: 12.4398 - val_mae: 2.7523\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 18.4189 - mae: 3.0844 - val_loss: 12.4382 - val_mae: 2.7537\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 18.4030 - mae: 3.0822 - val_loss: 12.3958 - val_mae: 2.7401\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 18.3918 - mae: 3.0733 - val_loss: 12.4325 - val_mae: 2.7524\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 18.3757 - mae: 3.0792 - val_loss: 12.3991 - val_mae: 2.7443\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 18.3520 - mae: 3.0725 - val_loss: 12.3934 - val_mae: 2.7433\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 18.3371 - mae: 3.0714 - val_loss: 12.4079 - val_mae: 2.7486\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 18.3252 - mae: 3.0739 - val_loss: 12.3529 - val_mae: 2.7341\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 18.3100 - mae: 3.0648 - val_loss: 12.3761 - val_mae: 2.7413\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 18.2926 - mae: 3.0684 - val_loss: 12.3578 - val_mae: 2.7379\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 18.2740 - mae: 3.0642 - val_loss: 12.3505 - val_mae: 2.7379\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 18.2591 - mae: 3.0629 - val_loss: 12.3520 - val_mae: 2.7389\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 18.2434 - mae: 3.0628 - val_loss: 12.3375 - val_mae: 2.7355\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 18.2291 - mae: 3.0596 - val_loss: 12.3182 - val_mae: 2.7322\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 18.2143 - mae: 3.0556 - val_loss: 12.3322 - val_mae: 2.7365\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 18.2004 - mae: 3.0589 - val_loss: 12.3049 - val_mae: 2.7303\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 18.1871 - mae: 3.0528 - val_loss: 12.3226 - val_mae: 2.7358\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 18.1693 - mae: 3.0552 - val_loss: 12.3232 - val_mae: 2.7373\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 18.1563 - mae: 3.0547 - val_loss: 12.2618 - val_mae: 2.7224\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 18.1514 - mae: 3.0435 - val_loss: 12.3212 - val_mae: 2.7363\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 18.1385 - mae: 3.0571 - val_loss: 12.2634 - val_mae: 2.7230\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 18.1178 - mae: 3.0430 - val_loss: 12.2809 - val_mae: 2.7297\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 18.0969 - mae: 3.0450 - val_loss: 12.3333 - val_mae: 2.7413\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 18.0909 - mae: 3.0531 - val_loss: 12.2631 - val_mae: 2.7228\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 18.0885 - mae: 3.0375 - val_loss: 12.3274 - val_mae: 2.7363\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 18.0627 - mae: 3.0515 - val_loss: 12.3045 - val_mae: 2.7306\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 18.0460 - mae: 3.0476 - val_loss: 12.2588 - val_mae: 2.7215\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 18.0340 - mae: 3.0361 - val_loss: 12.2890 - val_mae: 2.7335\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 18.0166 - mae: 3.0429 - val_loss: 12.2502 - val_mae: 2.7274\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 17.9997 - mae: 3.0364 - val_loss: 12.2262 - val_mae: 2.7221\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 17.9871 - mae: 3.0327 - val_loss: 12.2711 - val_mae: 2.7314\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 17.9741 - mae: 3.0422 - val_loss: 12.2284 - val_mae: 2.7217\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 17.9587 - mae: 3.0339 - val_loss: 12.2170 - val_mae: 2.7206\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 17.9457 - mae: 3.0319 - val_loss: 12.2473 - val_mae: 2.7271\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 17.9381 - mae: 3.0389 - val_loss: 12.1651 - val_mae: 2.7089\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 17.9350 - mae: 3.0213 - val_loss: 12.2348 - val_mae: 2.7248\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 17.9128 - mae: 3.0371 - val_loss: 12.2225 - val_mae: 2.7213\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 17.8935 - mae: 3.0330 - val_loss: 12.1864 - val_mae: 2.7143\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 17.8878 - mae: 3.0223 - val_loss: 12.2551 - val_mae: 2.7297\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 17.8704 - mae: 3.0331 - val_loss: 12.2005 - val_mae: 2.7194\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 17.8533 - mae: 3.0225 - val_loss: 12.1851 - val_mae: 2.7142\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 17.8395 - mae: 3.0198 - val_loss: 12.2245 - val_mae: 2.7212\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 17.8330 - mae: 3.0293 - val_loss: 12.1741 - val_mae: 2.7107\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 17.8148 - mae: 3.0188 - val_loss: 12.1707 - val_mae: 2.7140\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 17.8028 - mae: 3.0176 - val_loss: 12.2179 - val_mae: 2.7249\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 17.7989 - mae: 3.0261 - val_loss: 12.1387 - val_mae: 2.7082\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 17.7869 - mae: 3.0106 - val_loss: 12.1858 - val_mae: 2.7152\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 17.7654 - mae: 3.0208 - val_loss: 12.1926 - val_mae: 2.7162\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 17.7556 - mae: 3.0216 - val_loss: 12.1341 - val_mae: 2.7074\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 17.7488 - mae: 3.0081 - val_loss: 12.1829 - val_mae: 2.7175\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 17.7295 - mae: 3.0176 - val_loss: 12.1867 - val_mae: 2.7169\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 17.7190 - mae: 3.0180 - val_loss: 12.1261 - val_mae: 2.7055\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 17.7177 - mae: 3.0037 - val_loss: 12.1912 - val_mae: 2.7165\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 17.6966 - mae: 3.0166 - val_loss: 12.1717 - val_mae: 2.7143\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 17.6808 - mae: 3.0116 - val_loss: 12.1195 - val_mae: 2.7087\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 17.6790 - mae: 3.0004 - val_loss: 12.1691 - val_mae: 2.7193\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 17.6659 - mae: 3.0110 - val_loss: 12.1363 - val_mae: 2.7116\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 17.6452 - mae: 3.0055 - val_loss: 12.1276 - val_mae: 2.7070\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 17.6391 - mae: 3.0057 - val_loss: 12.1473 - val_mae: 2.7092\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 17.6287 - mae: 3.0089 - val_loss: 12.1318 - val_mae: 2.7087\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 17.6123 - mae: 3.0036 - val_loss: 12.1178 - val_mae: 2.7107\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 17.6041 - mae: 2.9999 - val_loss: 12.1405 - val_mae: 2.7173\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 17.5946 - mae: 3.0036 - val_loss: 12.1015 - val_mae: 2.7121\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 17.5808 - mae: 2.9955 - val_loss: 12.1049 - val_mae: 2.7100\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 17.5668 - mae: 2.9966 - val_loss: 12.1307 - val_mae: 2.7098\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 17.5593 - mae: 3.0018 - val_loss: 12.1060 - val_mae: 2.7047\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 17.5455 - mae: 2.9958 - val_loss: 12.1146 - val_mae: 2.7084\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 17.5346 - mae: 2.9959 - val_loss: 12.1529 - val_mae: 2.7163\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 17.5269 - mae: 3.0005 - val_loss: 12.1143 - val_mae: 2.7107\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 17.5126 - mae: 2.9900 - val_loss: 12.1371 - val_mae: 2.7134\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 17.4992 - mae: 2.9918 - val_loss: 12.1476 - val_mae: 2.7136\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 17.4887 - mae: 2.9929 - val_loss: 12.1219 - val_mae: 2.7089\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 17.4794 - mae: 2.9873 - val_loss: 12.1660 - val_mae: 2.7144\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 17.4681 - mae: 2.9940 - val_loss: 12.1571 - val_mae: 2.7118\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 17.4560 - mae: 2.9920 - val_loss: 12.1273 - val_mae: 2.7062\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 17.4467 - mae: 2.9862 - val_loss: 12.1418 - val_mae: 2.7107\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 17.4342 - mae: 2.9883 - val_loss: 12.1451 - val_mae: 2.7148\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 17.4233 - mae: 2.9871 - val_loss: 12.1214 - val_mae: 2.7130\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 17.4141 - mae: 2.9818 - val_loss: 12.1089 - val_mae: 2.7102\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 17.4029 - mae: 2.9800 - val_loss: 12.1266 - val_mae: 2.7095\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 17.3911 - mae: 2.9846 - val_loss: 12.1182 - val_mae: 2.7049\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 17.3815 - mae: 2.9835 - val_loss: 12.0900 - val_mae: 2.7014\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 17.3740 - mae: 2.9777 - val_loss: 12.1442 - val_mae: 2.7095\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 17.3645 - mae: 2.9855 - val_loss: 12.0966 - val_mae: 2.7062\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 17.3543 - mae: 2.9730 - val_loss: 12.1243 - val_mae: 2.7122\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 17.3409 - mae: 2.9761 - val_loss: 12.1407 - val_mae: 2.7136\n",
            "Epoch 984/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 17.3340 - mae: 2.9783 - val_loss: 12.0829 - val_mae: 2.7013\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 17.3276 - mae: 2.9673 - val_loss: 12.1375 - val_mae: 2.7063\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 17.3119 - mae: 2.9770 - val_loss: 12.1151 - val_mae: 2.7033\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 17.2983 - mae: 2.9719 - val_loss: 12.0951 - val_mae: 2.7027\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 17.2903 - mae: 2.9678 - val_loss: 12.1267 - val_mae: 2.7093\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 17.2815 - mae: 2.9738 - val_loss: 12.0895 - val_mae: 2.7038\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 17.2696 - mae: 2.9674 - val_loss: 12.0862 - val_mae: 2.7017\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 17.2587 - mae: 2.9663 - val_loss: 12.1092 - val_mae: 2.7025\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 17.2511 - mae: 2.9699 - val_loss: 12.0581 - val_mae: 2.6966\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 17.2436 - mae: 2.9598 - val_loss: 12.0894 - val_mae: 2.7000\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 17.2299 - mae: 2.9663 - val_loss: 12.0843 - val_mae: 2.7004\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 17.2198 - mae: 2.9651 - val_loss: 12.0674 - val_mae: 2.6985\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 17.2110 - mae: 2.9593 - val_loss: 12.0983 - val_mae: 2.7017\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 17.2003 - mae: 2.9641 - val_loss: 12.0814 - val_mae: 2.7005\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 17.1903 - mae: 2.9603 - val_loss: 12.0731 - val_mae: 2.6995\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 17.1804 - mae: 2.9600 - val_loss: 12.0711 - val_mae: 2.6990\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 17.1710 - mae: 2.9610 - val_loss: 12.0671 - val_mae: 2.6969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict = modelo.predict(x_teste)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPi6zAaWDxDs",
        "outputId": "4b64e380-dcd2-4945-d136-9227912547c0"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "df_results = pd.DataFrame()\n",
        "df_results['valor_real'] = y_teste\n",
        "df_results['valor_predito']= predict\n",
        "df_results.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "ic7vdxFJGQ54",
        "outputId": "3608185e-0cfb-4935-acc1-85e2c0e97c84"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   valor_real  valor_predito\n",
              "0        13.2       6.499384\n",
              "1        44.0      38.930420\n",
              "2        48.3      37.904251\n",
              "3        12.3      13.183693\n",
              "4        25.2      26.640862\n",
              "5        25.0      28.861641\n",
              "6        19.4      20.866650\n",
              "7        29.4      34.167637\n",
              "8        36.1      30.821789\n",
              "9        29.0      26.650728"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aadbbb56-7549-45bf-ad54-2fb0c59e98f1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>valor_real</th>\n",
              "      <th>valor_predito</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13.2</td>\n",
              "      <td>6.499384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44.0</td>\n",
              "      <td>38.930420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>48.3</td>\n",
              "      <td>37.904251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12.3</td>\n",
              "      <td>13.183693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25.2</td>\n",
              "      <td>26.640862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>25.0</td>\n",
              "      <td>28.861641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>19.4</td>\n",
              "      <td>20.866650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>29.4</td>\n",
              "      <td>34.167637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>36.1</td>\n",
              "      <td>30.821789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>29.0</td>\n",
              "      <td>26.650728</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aadbbb56-7549-45bf-ad54-2fb0c59e98f1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aadbbb56-7549-45bf-ad54-2fb0c59e98f1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aadbbb56-7549-45bf-ad54-2fb0c59e98f1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt \n",
        "\n",
        "# Calcula a mtrica rmse \n",
        "rmse = (np.sqrt(mean_squared_error(y_teste, predict)))"
      ],
      "metadata": {
        "id": "98C5lg9yzTsh"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Performance do modelo avaliado com os dados de teste: \")\n",
        "print('\\nRMSE : {}'.format(rmse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ob5qNfEzou5",
        "outputId": "1b603ced-3dad-4da1-d589-10432308cb82"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance do modelo avaliado com os dados de teste: \n",
            "\n",
            "RMSE : 3.4737751208497656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go \n",
        "\n",
        "# cria uma figura \n",
        "fig = go.Figure()\n",
        "\n",
        "# Linha com os dados de teste \n",
        "fig.add_trace(go.Scatter(x=df_results.index,\n",
        "                         y=df_results.valor_real,\n",
        "                         mode='lines+markers',\n",
        "                         name='Valor Real'))\n",
        "\n",
        "# Linha com os dados preditos \n",
        "fig.add_trace(go.Scatter(x=df_results.index,\n",
        "                         y=df_results.valor_predito,\n",
        "                         mode='lines+markers',\n",
        "                         name='Valor Predito Rede'))\n",
        "\n",
        "# Plota a figura \n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "m4LKa5wv48WO",
        "outputId": "cb543a99-05a9-476d-a9d0-861115af6791"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"46554fcc-6023-4e90-b5b4-727cc6eb402a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"46554fcc-6023-4e90-b5b4-727cc6eb402a\")) {                    Plotly.newPlot(                        \"46554fcc-6023-4e90-b5b4-727cc6eb402a\",                        [{\"mode\":\"lines+markers\",\"name\":\"Valor Real\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151],\"y\":[13.2,44.0,48.3,12.3,25.2,25.0,19.4,29.4,36.1,29.0,19.1,19.0,20.6,15.0,16.8,14.4,23.0,19.8,15.6,25.3,20.5,19.8,19.1,24.5,10.5,24.1,23.1,19.5,17.2,23.7,20.0,19.6,24.5,29.6,33.2,22.5,18.8,18.7,19.9,29.8,15.2,50.0,17.5,33.8,30.1,23.8,14.9,22.0,13.1,15.6,22.8,50.0,31.5,37.6,22.8,24.4,33.4,27.5,28.4,24.7,16.6,19.7,18.1,14.5,5.0,20.4,23.2,20.1,36.4,14.1,17.1,22.2,17.8,17.1,10.2,23.3,36.0,43.5,11.8,50.0,20.6,34.6,22.0,33.0,23.3,23.0,25.0,19.3,5.6,25.0,20.8,11.8,24.2,15.6,20.5,21.4,24.3,24.1,48.5,7.2,14.9,22.9,18.7,26.2,21.5,13.5,50.0,21.6,37.3,24.8,20.8,16.2,24.0,31.1,20.0,8.8,16.5,31.6,21.7,20.3,27.1,19.5,18.6,9.6,27.9,17.2,16.1,7.4,13.4,17.4,7.0,20.4,11.7,18.7,22.5,22.9,50.0,16.3,28.7,10.8,21.9,20.9,29.1,18.2,21.2,10.2,19.3,21.4,23.9,35.2,22.0,16.1],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"Valor Predito Rede\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151],\"y\":[6.49938440322876,38.930419921875,37.90425109863281,13.183692932128906,26.64086151123047,28.86164093017578,20.866649627685547,34.16763687133789,30.821788787841797,26.650728225708008,17.708406448364258,14.818628311157227,25.68396759033203,19.800594329833984,19.377443313598633,11.342984199523926,25.238418579101562,22.108795166015625,13.894508361816406,26.716415405273438,22.62587547302246,20.091339111328125,20.791994094848633,20.522308349609375,10.721403121948242,21.536556243896484,24.203269958496094,22.751510620117188,16.182119369506836,31.269821166992188,18.257654190063477,19.22884750366211,26.236915588378906,21.863365173339844,31.124759674072266,18.54515266418457,18.024328231811523,17.867801666259766,16.634815216064453,33.03981399536133,15.86109733581543,47.25762939453125,19.566898345947266,33.779117584228516,28.756851196289062,22.807762145996094,14.884380340576172,25.252029418945312,11.788545608520508,18.32405662536621,27.3618106842041,46.07084655761719,36.22760772705078,43.28469467163086,22.462366104125977,22.097000122070312,34.22807312011719,21.548358917236328,27.022480010986328,25.98421859741211,17.468673706054688,21.61176300048828,17.387065887451172,14.495645523071289,9.179706573486328,23.431306838989258,14.59842300415039,19.441028594970703,36.36986541748047,15.15304183959961,21.383441925048828,25.702686309814453,17.46981430053711,19.589487075805664,12.700935363769531,22.296157836914062,40.58217239379883,42.81462478637695,13.67081069946289,45.61634063720703,23.032011032104492,32.009315490722656,26.257946014404297,23.380210876464844,23.596920013427734,21.337963104248047,33.381141662597656,22.938926696777344,11.230485916137695,31.944677352905273,15.831934928894043,13.235649108886719,25.930137634277344,14.707042694091797,19.041961669921875,22.04891014099121,20.14923095703125,28.113765716552734,43.410797119140625,11.052810668945312,16.51552963256836,23.78388023376465,20.15999984741211,25.966480255126953,21.374401092529297,13.758852005004883,43.515316009521484,23.639293670654297,34.550235748291016,30.949129104614258,21.312820434570312,16.691165924072266,20.657590866088867,29.372726440429688,20.360166549682617,8.842569351196289,13.570671081542969,38.671905517578125,19.784378051757812,21.13068199157715,23.663089752197266,17.317346572875977,21.276704788208008,16.112394332885742,29.902202606201172,11.758594512939453,17.249162673950195,10.113106727600098,15.506298065185547,17.099916458129883,14.046125411987305,18.61223793029785,11.451255798339844,22.850162506103516,26.641380310058594,22.796798706054688,44.378684997558594,12.392415046691895,31.456178665161133,11.000561714172363,16.96192741394043,22.672584533691406,26.15764808654785,19.60085678100586,22.589996337890625,9.668216705322266,18.96819496154785,21.644296646118164,24.800823211669922,29.476537704467773,23.739133834838867,17.384719848632812],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('46554fcc-6023-4e90-b5b4-727cc6eb402a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}